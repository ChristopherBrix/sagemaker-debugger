{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging SageMaker Training Jobs with Tornasole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tornasole is an upcoming AWS service designed to be a debugger for machine learning models. It lets you go beyond just looking at scalars like losses and accuracies during training and gives you full visibility into all tensors 'flowing through the graph' during training or inference.\n",
    "\n",
    "Using Tornasole is a two step process:\n",
    "\n",
    "### Saving tensors\n",
    "\n",
    "This library, intended to be used with Tornasole, helps you save tensors from a running TensorFlow job. It lets you collect the tensors you want at the frequency that you want, and save them for analysis.\n",
    "\n",
    "### Analysis\n",
    "\n",
    "The analysis of tensors saved requires the package tornasole_rules. Please refer to the documentation for the above package for more details about how to install and analyze. That said, we do provide a few example analysis commands below so as to provide an end to end flow. These require the tornasole_rules package to be installed.\n",
    "\n",
    "This example walks through an example which guides through installation of the required components for emitting tensors in a SageMaker training job and applying a rule over the tensors to monitor the live status of the job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "As a first step, we'll do the installation of required tools which will allow emission of tensors (saving tensors) and application of rules to analyze them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://tornasole-external-preview-use1/sdk/sagemaker-1.35.2.dev0.tar.gz .\n",
    "!pip install sagemaker-1.35.2.dev0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://tornasole-external-preview-use1/sdk/sagemaker-tornasole.json .\n",
    "!aws configure add-model --service-model sagemaker-tornasole.json --service-name sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've completed the setup, we're ready to spin off a training job with debugging enabled\n",
    "\n",
    "## Training with Script Mode\n",
    "\n",
    "We'll be training a mxnet gluon model for FashonMNIST dataset. This will be done using SageMaker MXNet Container with Script Mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs\n",
    "\n",
    "Configuring the inputs for the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point_script = '../scripts/mnist_gluon_basic_hook_demo.py'\n",
    "docker_image_name= '072677473360.dkr.ecr.us-west-2.amazonaws.com/tornasole-preprod-mxnet-1.4.1-cpu:latest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters\n",
    "\n",
    "Now we'll call the MXNet Estimator to kick off a training job. The new parameters in the Estimator to look out for are\n",
    "\n",
    "##### `debug` (bool)\n",
    "This indicates that debugging should be enabled for the training job. Setting this as `True` would make Tornasole available for use with the job\n",
    "\n",
    "##### `tornasole_hook_config_json` (str)\n",
    "This is a stringified form of the json configuration you need to instantiate the Tornasole hook in your training script.\n",
    "\n",
    "##### `rules_specification` (list[*dict*])\n",
    "This is a list of python dictionaries, where each `dict` is of the following form:\n",
    "```\n",
    "{\n",
    "    \"RuleName\": <str> # The name of the class implementing the Tornasole Rule interface. (required)\n",
    "    \"SourceS3Uri\": <str> # S3 URI of the rule script containing the class in 'RuleName'. If left empty, it would look for the class in one of the First Party rules already provided to you by Amazon. If not, SageMaker will try to look for the rule class in the script\n",
    "    \"InstanceType\": <str> # The ml instance type in which the rule evaluation should run\n",
    "    \"VolumeSizeInGB\": <int> # The volume size to store the runtime artifacts from the rule evaluation\n",
    "    \"RuntimeConfigurations\": {\n",
    "        # Map defining the parameters required to instantiate the Rule class and invoke the rule\n",
    "        <str>: <str>\n",
    "    }\n",
    "}\n",
    "```\n",
    "#### Storage\n",
    "The tensors, by default, will be saved to the S3 output location path of the training job, under the folder **`/tensors-<job name>`**. This is done to preserve separate paths for tensors from different training job so that the Rules can be evaluated correctly. Re-using the same path for different training jobs will result in rule to be evaluated incorrectly.\n",
    "\n",
    "If you don't provide an output path, SageMaker will create one for you as\n",
    "**`s3://sagemaker-<region>-<account_id>/`**\n",
    "\n",
    "#### Estimator\n",
    "See the way we instantiate the estimator below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'tornasole_path' : '/opt/ml/output/tensors', 'random_seed' : True,  'num_steps': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MXNet(role=sagemaker.get_execution_role(),\n",
    "                  base_job_name='mxnet-trsl-test-nb',\n",
    "                  train_instance_count=1,\n",
    "                  train_instance_type='ml.m4.xlarge',\n",
    "                  image_name=docker_image_name,\n",
    "                  entry_point=entry_point_script,\n",
    "                  hyperparameters=hyperparameters,\n",
    "                  framework_version='1.4.1',\n",
    "                  debug=True,\n",
    "                  py_version='py3',\n",
    "                  rules_specification=[\n",
    "                      {\n",
    "                          \"RuleName\": \"VanishingGradient\",\n",
    "                          \"InstanceType\": \"ml.c5.4xlarge\",\n",
    "                          \"VolumeSizeInGB\": 10,\n",
    "                          \"RuntimeConfigurations\": {\n",
    "                              \"end-step\": \"5\"\n",
    "                          }\n",
    "                      }\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To kick off the job, we call the `fit()` method on the MXNet estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "As a result of the above command, SageMaker will spin off 2 training jobs for you - the first one being the job which produces the tensors to be analyzed and the second one, which evaluates or analyzes the rule you asked it to in `rules_specification`\n",
    "\n",
    "You'll notice that while the Training Job completes, the weight update ratio blows of step 233 onwards. Thus, the rule execution job which was started as a result of this training job, fails.\n",
    "\n",
    "### Training Job\n",
    "You can go to the console to get the training job starting with **mxnet-trsl-ibhatt-test-nb** or optionally, do a list call and get the job arn from there. \n",
    "\n",
    "### Accessing the Rule Execution Job\n",
    "To get the rule execution job that SageMaker started for you, go to the SageMaker console and under Training Jobs find the job name starting with 'WeightUpdateRatio'. Optionally, you can do a Describe API call on the parent training job and get the job name from `RuleMonitoringStatus` blob\n",
    "```\n",
    "Failure reason\n",
    "ClientError: RuleEvaluationConditionMet: Rule evaluation resulted in the condition being met Traceback (most recent call last): File \"train.py\", line 214, in execute exec(_SYMBOLIC_INVOKE_RULE.format(self.start_step, self.end_step), globals(), exec_local) File \"<string>\", line 2, in <module> File \"/usr/local/lib/python3.7/site-packages/tornasole/rules/rule_invoker.py\", line 82, in invoke_rule raise e File \"/usr/local/lib/python3.7/site-packages/tornasole/rules/rule_invoker.py\", line 77, in invoke_rule rule_obj.invoke(step) File \"/usr/local/lib/python3.7/site-packages/tornasole/rules/rule.py\", line 103, in invoke raise RuleEvaluationConditionMet tornasole.exceptions.RuleEvaluationConditionMet: Rule evaluation resulted in the condition being met \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.describe_rule_execution_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point_script = '../scripts/mnist_gluon_vg_demo.py'\n",
    "bad_hyperparameters = {'tornasole_path' : '/opt/ml/output/tensors', 'random_seed' : True,  'num_steps': 33, 'tornasole_frequency' : 30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MXNet(role=sagemaker.get_execution_role(),\n",
    "                  base_job_name='mxnet-trsl-test-nb',\n",
    "                  train_instance_count=1,\n",
    "                  train_instance_type='ml.m4.xlarge',\n",
    "                  image_name=docker_image_name,\n",
    "                  entry_point=entry_point_script,\n",
    "                  hyperparameters=bad_hyperparameters,\n",
    "                  framework_version='1.4.1',\n",
    "                  debug=True,\n",
    "                  py_version='py3',\n",
    "                  rules_specification=[\n",
    "                      {\n",
    "                          \"RuleName\": \"VanishingGradient\",\n",
    "                          \"InstanceType\": \"ml.c5.4xlarge\",\n",
    "                          \"VolumeSizeInGB\": 10,\n",
    "                          \"RuntimeConfigurations\": {\n",
    "                              \"start-step\" : \"1\",\n",
    "                              \"end-step\": \"33\"\n",
    "                          }\n",
    "                      }\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.describe_rule_execution_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
