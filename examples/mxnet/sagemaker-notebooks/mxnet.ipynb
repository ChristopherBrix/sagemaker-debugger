{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging SageMaker Training Jobs with Tornasole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tornasole is a new capability of Amazon SageMaker that allows debugging machine learning training. \n",
    "It lets you go beyond just looking at scalars like losses and accuracies during training and gives \n",
    "you full visibility into all tensors 'flowing through the graph' during training. Tornasole helps you to monitor your training in near real time using rules and would provide you alerts, once it has detected inconsistency in training flow.\n",
    "\n",
    "Using Tornasole is a two step process: Saving tensors and Analysis. Let's look at each one of them closely.\n",
    "\n",
    "### Saving tensors\n",
    "\n",
    "Tensors define the state of the training job at any particular instant in its lifecycle. Tornasole exposes a library which allows you to capture these tensors and save them for analysis\n",
    "\n",
    "### Analysis\n",
    "\n",
    "Analysis of the tensors emitted is captured by the Tornasole concept called ***Rules***. On a very broad level, \n",
    "a rule is a python code used to detect certain conditions during training. Some of the conditions that a data scientist training a deep learning model may care about are monitoring for gradients getting too large or too small, detecting overfitting, and so on.\n",
    "Tornasole will come pre-packaged with certain rules. Users can write their own rules using the Tornasole APIs.\n",
    "You can also analyze raw tensor data outside of the Rules construct in say, a Sagemaker notebook, using Tornasole's full set of APIs. \n",
    "Please refer [DeveloperGuide_Rules.md](../../../../rules/DeveloperGuide_Rules.md) for more details about analysis.\n",
    "\n",
    "This example guides you through installation of the required components for emitting tensors in a \n",
    "SageMaker training job and applying a rule over the tensors to monitor the live status of the job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "As a first step, we'll do the installation of required tools which will allow emission of tensors (saving tensors) and application of rules to analyze them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://tornasole-external-preview-use1/sdk/sagemaker-1.35.2.dev0.tar.gz .\n",
    "!pip install sagemaker-1.35.2.dev0.tar.gz\n",
    "!aws s3 cp s3://tornasole-external-preview-use1/sdk/sagemaker-tornasole.json .\n",
    "!aws configure add-model --service-model sagemaker-tornasole.json --service-name sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training MXNet models in SageMaker with Tornasole\n",
    "\n",
    "We'll be training a mxnet gluon model for FashonMNIST dataset in this notebook with Tornasole enabled and monitor the training jobs with Tornasole's Rules. This will be done using SageMaker MXNet 1.4.1 Container with Script Mode. Note that Tornasole currently only works with python3, so be sure to set `py_version='py3'` when creating SageMaker Estimator.\n",
    "\n",
    "\n",
    "Let us first train a simple example training script mnist_gluon_vg_demo.py with Tornasole enabled in SageMaker using the SageMaker Estimator API, along with a VanishingGradient Rule to monitor the training job in realtime. A Tornasole Rule is essentially python code which analyses tensors saved by tornasole and validates some condition. VanishingGradient rule is a first party (1P) rule provided by Tornasole. During training, Tornasole will capture tensors as specified in its configuration and VanishingGradient Rule job will monitor whether any gradient tensor has reached 0. The rule will emit a cloudwatch event if it finds an vanishing gradient tensor during training.\n",
    "\n",
    "## Enable Tornasole in the training script\n",
    "\n",
    "Integrating Tornasole into the training job can be accomplished by following steps below.\n",
    "\n",
    "### Import the tornasole_hook package\n",
    "Import the TornasoleHook class along with other helper classes in your training script as shown below\n",
    "\n",
    "```\n",
    "from tornasole.mxnet.hook import TornasoleHook\n",
    "from tornasole.mxnet import SaveConfig, Collection\n",
    "```\n",
    "\n",
    "### Instantiate and initialize tornasole hook\n",
    "\n",
    "```\n",
    "    # Create SaveConfig that instructs engine to log graph tensors every 10 steps.\n",
    "    save_config = SaveConfig(save_interval=10)\n",
    "    # Create a hook that logs tensors of weights, biases and gradients while training the model.\n",
    "    hook = TornasoleHook(save_config=save_config)\n",
    "```\n",
    "\n",
    "### Register Tornasole hook to the model before starting of the training.\n",
    "\n",
    "### NOTE: The tornasole hook can only be registered to Gluon Non-hybrid models.\n",
    "\n",
    "After creating or loading the desired model, users can register the hook with the model as shown below.\n",
    "\n",
    "```\n",
    "net = create_gluon_model()\n",
    " # Apply hook to the model (e.g. instruct engine to recognize hook configuration\n",
    " # and enable mode in which engine will log graph tensors\n",
    "hook.register_hook(net)\n",
    "```\n",
    "\n",
    "#### Set the mode\n",
    "Tornasole has the concept of modes (TRAIN, EVAL, PREDICT) to separate out different modes of the jobs.\n",
    "Set the mode you are running in your job. Every time the mode changes in your job, please set the current mode. This helps you group steps by mode, for easier analysis. Setting the mode is optional but recommended. If you do not specify this, Tornasole saves all steps under a `GLOBAL` mode. \n",
    "```\n",
    "hook.set_mode(ts.modes.TRAIN)\n",
    "```\n",
    "\n",
    "Refer [DeveloperGuide_MXNet.md](../../DeveloperGuide_MXNet.md) for more details on the APIs Tornasole provides to help you save tensors.\n",
    "\n",
    "\n",
    "### Docker Images with Tornasole\n",
    "\n",
    "We have built SageMaker MXNet containers with Tornasole. You can use them from ECR from SageMaker. Here are the links to the images. Please use the image from the appropriate region in which you want your jobs to run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "# Below changes the region to be one where this notebook is running\n",
    "REGION = boto3.Session().region_name\n",
    "TAG='latest'\n",
    "\n",
    "cpu_docker_image_name= '072677473360.dkr.ecr.{}.amazonaws.com/tornasole-preprod-mxnet-1.4.1-cpu:{}'.format(REGION, TAG)\n",
    "gpu_docker_image_name= '072677473360.dkr.ecr.{}.amazonaws.com/tornasole-preprod-mxnet-1.4.1-gpu:{}'.format(REGION, TAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the inputs for the training job\n",
    "\n",
    "Now we'll call the Sagemaker MXNet Estimator to kick off a training job along with the VanishingGradient rule to monitor the job.\n",
    "\n",
    "The 'entry_point_script' points to the MXNet training script that has the TornasoleHook integrated.\n",
    "\n",
    "The 'hyperparameters' are the parameters that will be passed to the training script.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point_script = '../scripts/mnist_gluon_vg_demo.py'\n",
    "bad_hyperparameters = {'random_seed' : True,  'num_steps': 33, 'tornasole_frequency' : 30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_simple_estimator = MXNet(role=sagemaker.get_execution_role(),\n",
    "                  base_job_name='mxnet-tornasole-simple-demo',\n",
    "                  train_instance_count=1,\n",
    "                  train_instance_type='ml.m4.xlarge',\n",
    "                  image_name=cpu_docker_image_name,\n",
    "                  entry_point=entry_point_script,\n",
    "                  hyperparameters=bad_hyperparameters,\n",
    "                  framework_version='1.4.1',\n",
    "                  debug=True,\n",
    "                  py_version='py3',\n",
    "                  # These are Tornasole specific parameters, \n",
    "                  # debug= True means rule specified in rules_specification \n",
    "                  # will run as rule job. \n",
    "                  # Below, we specify to run the first party rule VanishingGradient\n",
    "                  # on a ml.c5.4xlarge instance\n",
    "                  rules_specification=[\n",
    "                      {\n",
    "                          \"RuleName\": \"VanishingGradient\",\n",
    "                          \"InstanceType\": \"ml.c5.4xlarge\",\n",
    "                          \"VolumeSizeInGB\": 10,\n",
    "                          \"RuntimeConfigurations\": {\n",
    "                              \"end-step\": \"33\"\n",
    "                          }\n",
    "                      }\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_simple_estimator.fit(wait=False)\n",
    "# This is a fire and forget event. By setting wait=False, we just submit the job to run in the background.\n",
    "# In the background SageMaker will spin off 1 training job and 1 rule job for you.\n",
    "# Please follow this notebook to see status of the training job and the rule job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Result\n",
    "\n",
    "As a result of the above command, SageMaker will spin off 1 training job and 1 rule job for you - the first one being the job which produces the tensors to be analyzed and the second one, which analyzes the tensors to check if there are any tensors that demonstrate the vanishing gradient issue during training.\n",
    "\n",
    "### Describing the training job\n",
    "\n",
    "We can check the status of the training job by running the following command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below command will give the status of training job\n",
    "# Note: In the output of below command you will see DebugConfig parameter \n",
    "\n",
    "job_name = sagemaker_simple_estimator.latest_training_job.name\n",
    "\n",
    "client = sagemaker_simple_estimator.sagemaker_session.sagemaker_client\n",
    "\n",
    "description = client.describe_training_job(TrainingJobName=job_name)\n",
    "\n",
    "# uncomment next line to see full details of training job \n",
    "# description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The status of the training job can be seen below\n",
    "description['TrainingJobStatus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your training job is started SageMaker will spin up a rule execution job to run the ExplodingTensor rule.\n",
    "\n",
    "### Tornasole specific parameters in the description\n",
    "\n",
    "DebugConfig parameter has details about Tornasole related configuration. The key parameters to look for below are\n",
    "\n",
    "*S3OutputPath* : This is the path where output tensors from tornasole is getting saved.\n",
    "\n",
    "*RuleConfig* : This parameter tells about the rule config parameter that was passed when creating the trainning job. In this you should be able to see details of the rule that ran for training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description['DebugConfig']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Check the status of the Rule Execution Job\n",
    "\n",
    "To get the rule execution job that SageMaker started for you, run the command below and it shows you the `RuleName`, `RuleStatus`, `FailureReason` if any, and `RuleExecutionJobArn`. If the tensors meets a rule evaluation condition, the rule execution job throws a client error with `FailureReason: RuleEvaluationConditionMet`. These details are also available as part of the response description above under: description['RuleMonitoringStatuses']\n",
    "\n",
    "The logs of the training job are available in the `Cloudwatch Logstream` /aws/sagemaker/TrainingJobs with `RuleExecutionJobArn`.\n",
    "\n",
    "You will see that once the rule execution job starts, that it identifies the vanishing gradient situation in the training job, raises the `RuleEvaluationConditionMet` exception and ends the job.\n",
    "\n",
    "**Note: The next cell blocks till the rule execution job ends. You can stop it at any point to proceed to the rest of the notebook. Once it says RuleStatus is Started, and shows the RuleExecutionJobArn, you can look at the status of the rule being monitored. At that point, we can also look at the logs as shown in the next cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_simple_estimator.describe_rule_execution_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the logs of the Rule Execution Job\n",
    "\n",
    "If you want to access the logs of a particular rule job name, you can do the following. First, you need to get the rule job name (RuleExecutionJobArn field from the training job description). Note that this is only available after the rule job reaches Started stage. Hence the next cell waits till the job name is available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "rule_descr = client.describe_training_job(TrainingJobName=job_name)['RuleMonitoringStatuses']\n",
    "print('Waiting for rule execution job to start')\n",
    "while 'RuleExecutionJobArn' not in rule_descr[0]:\n",
    "    sleep(5)\n",
    "    rule_descr = client.describe_training_job(TrainingJobName=job_name)['RuleMonitoringStatuses']\n",
    "\n",
    "rule_job_arn = rule_descr[0]['RuleExecutionJobArn']\n",
    "print('Rule execution job has started. The job ARN is {}'.format(rule_job_arn))\n",
    "rule_job_name = rule_job_arn.split('/')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can attach to this job to see its logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "vanishing_gradient_tensor = Estimator.attach(rule_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receive a CloudWatch Event for Rules\n",
    "When the status of training job or rule execution job change (i.e. starting, failed), TrainingJobStatus [CloudWatch events](https://docs.aws.amazon.com/sagemaker/latest/dg/cloudwatch-events.html) are emitted. You can see in the response to `describe_rule_execution_jobs()` above, the details about the cloudwatch event that was emitted due to rule success/failure. It would look like the following. \n",
    "> Created CW event Rule: arn:aws:events:us-east-2:072677473360:rule/RuleEvaluationConditionMetRule-tornasole-simple-demo-ExplodingTe\n",
    "> Please monitor the rule job statuses by going to CloudWatch->Events->Rule->Monitoring\n",
    "\n",
    "More details on this, [below](#CloudWatch-Event-Integration-for-Rules)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making this a good run\n",
    "\n",
    "In above example, we saw how a VanishingGradient Rule was run which analyzed the tensors when training was running and produced an alert in form of cloudwatch event.\n",
    "\n",
    "You can create the estimator with following *entry_point_script* and *bad_hyperparameters*. start a new training job.  You will see that the Vanishing Gradient rule is not fired in that case as no tensors demonstrate the vanishing gradient issue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point_script = '../scripts/mnist_gluon_basic_hook_demo.py'\n",
    "good_hyperparameters = {'random_seed' : True,  'num_steps': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_estimator = MXNet(role=sagemaker.get_execution_role(),\n",
    "                  base_job_name='mxnet-trsl-test-nb',\n",
    "                  train_instance_count=1,\n",
    "                  train_instance_type='ml.m4.xlarge',\n",
    "                  image_name=cpu_docker_image_name,\n",
    "                  entry_point=entry_point_script,\n",
    "                  hyperparameters=good_hyperparameters,\n",
    "                  framework_version='1.4.1',\n",
    "                  debug=True,\n",
    "                  py_version='py3',\n",
    "                  rules_specification=[\n",
    "                      {\n",
    "                          \"RuleName\": \"VanishingGradient\",\n",
    "                          \"InstanceType\": \"ml.c5.4xlarge\",\n",
    "                          \"VolumeSizeInGB\": 10,\n",
    "                          \"RuntimeConfigurations\": {\n",
    "                              \"start-step\" : \"1\",\n",
    "                              \"end-step\": \"5\"\n",
    "                          }\n",
    "                      }\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_estimator.describe_rule_execution_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enabling Tornasole with SageMaker\n",
    "#### Storage\n",
    "The tensors saved by Tornasole are, by default, stored in the S3 output path of the training job, under the folder **`/tensors-<job name>`**. This is done to ensure that we don't end up accidentally overwriting the tensors from a training job with the others. Rules evaluation require separation of the tensors paths to be evaluated correctly.\n",
    "\n",
    "If you don't provide an S3 output path to the estimator, SageMaker creates one for you as: **`s3://sagemaker-<region>-<account_id>/`**\n",
    "\n",
    "This path is used to create a Tornasole Trial taken by Rules (see below).\n",
    "\n",
    "#### New Parameters \n",
    "The new parameters in Sagemaker Estimator to look out for are\n",
    "\n",
    "- `debug` :(bool)\n",
    "This indicates that debugging should be enabled for the training job. \n",
    "Setting this as `True` would make Tornasole available for use with the job\n",
    "\n",
    "- `rules_specification`: (list[*dict*])\n",
    "You can specify any number of rules to monitor your SageMaker training job. This parameter takes a list of python dictionaries, one for each rule you want to enable. Each `dict` is of the following form:\n",
    "```\n",
    "{\n",
    "    \"RuleName\": <str>       \n",
    "        # The name of the class implementing the Tornasole Rule interface. (required)\n",
    "\n",
    "    \"SourceS3Uri\": <str>    \n",
    "        # S3 URI of the rule script containing the class in 'RuleName'. \n",
    "        # This is not required if you want to use one of the\n",
    "        # First Party rules provided to you by Amazon. \n",
    "        # In such a case you can leave it empty or not pass it. If you want to run a custom rule \n",
    "        # defined by you, you will need to define the custom rule class in a python \n",
    "        # file and provide it to SageMaker as a S3 URI. \n",
    "        # SageMaker will fetch this file and try to look for the rule class \n",
    "        # identified by RuleName in this file.\n",
    "    \n",
    "    \"InstanceType\": <str>   \n",
    "        # The ML instance type which should be used to run the rule evaluation job\n",
    "        \n",
    "    \"VolumeSizeInGB\": <int> \n",
    "        # The volume size to store the runtime artifacts from the rule evaluation \n",
    "        \n",
    "    \"RuntimeConfigurations\": {\n",
    "        # Map defining the parameters required to instantiate the Rule class and\n",
    "        # parameters regarding invokation of the rule (start-step and end-step)\n",
    "        # This can be any parameter taken by the rule. \n",
    "        # Every value here needs to be a string. \n",
    "        # So when you write custom rules, ensure that you can parse each argument from a string.\n",
    "        #\n",
    "        # PARAMS CAN BE\n",
    "        #\n",
    "        # STANDARD PARAMS FOR RULE EXECUTION\n",
    "        # \"start-step\": <str>\n",
    "        # \"end-step\": <str>\n",
    "        # \"other-trials-paths\": <str> (';' separated list of s3 paths as a string)\n",
    "        # \"logging-level\": <str> (can be one of \"CRITICAL\", \"FATAL\", \"ERROR\", \n",
    "        #                         \"WARNING\", \"WARN\", \"DEBUG\", \"NOTSET\")\n",
    "        #\n",
    "        # ANY OTHER PARAMETER TAKEN BY THE RULE\n",
    "        # \"parameter\" : <str>\n",
    "        # <str>: <str>\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### Inputs\n",
    "Just a quick reminder if you are not familiar with script mode in SageMaker. You can pass command line arguments taken by your training script with a hyperparameter dictionary which gets passed to the SageMaker Estimator class. You can see this in the examples below.\n",
    "\n",
    "\n",
    "### Rules\n",
    "Rules are the medium by which Tornasole executes a certain piece of code regularly on different steps of the job.\n",
    "They can be used to assert certain conditions during training, and raise Cloudwatch Events based on them that you can\n",
    "use to process in any way you like. \n",
    "\n",
    "Tornasole comes with a set of **First Party rules** (1P rules).\n",
    "You can also write your own rules looking at these 1P rules for inspiration. \n",
    "Refer [DeveloperGuide_Rules.md](../../../../rules/DeveloperGuide_Rules.md) for more on the APIs you can use to write your own rules as well as descriptions for the 1P rules that we provide. \n",
    " \n",
    "Here we will talk about how to use Sagemaker to evalute these rules on the training jobs.\n",
    "\n",
    "\n",
    "##### 1P Rule \n",
    "If you want to use a 1P rule. Specify the RuleName field with the 1P RuleName, and the rule will be automatically applied. You can pass any parameters accepted by the rule as part of the RuntimeConfigurations dictionary. Rules constructor take trial as parameter.  \n",
    "A Trial in Tornasole's context refers to a training job. It is identified by the path where the saved tensors for the job are stored.  \n",
    "A rule takes a `base_trial` which refers to the job whose run invokes the rule execution. \n",
    "\n",
    "**Note:** A rule can be written to compare & analyze tensors across training jobs. A rule which needs to compare tensors across trials can be run by passing the argument `other_trials`. The argument `base_trial` will automatically be set by SageMaker when executing the rule. The parameter `other_trials` (if taken by the rule) can be passed by passing `other-trials-paths` in the RuntimeConfigurations dictionary. The value for this argument should be `;` separated list of S3 output paths where the tensors for those trials are stored.\n",
    "\n",
    "Here's a example of a complex configuration for the SimilarAcrossRuns (which accepts one other trial and a regex pattern) where we ask for the rule to be invoked for the steps between 10 and 100.\n",
    "\n",
    "``` \n",
    "rules_specification = [ \n",
    "    {\n",
    "      \"RuleName\": \"SimilarAcrossRuns\",\n",
    "      \"InstanceType\": \"ml.c5.4xlarge\",\n",
    "      \"VolumeSizeInGB\": 10,\n",
    "      \"RuntimeConfigurations\": {\n",
    "         \"other_trials\": \"s3://sagemaker-<region>-<account_id>/past-job\",\n",
    "         \"include_regex\": \".*\",\n",
    "         \"start-step\": \"10\",\n",
    "         \"end-step\": \"100\"\n",
    "       }\n",
    "    }\n",
    "]\n",
    "```\n",
    "List of 1P rules and details about the rules can be found in *First party rules* section in [DeveloperGuide_Rules.md](../../../../rules/DeveloperGuide_Rules.md)  \n",
    "\n",
    "\n",
    "##### Custom rule\n",
    "In this case you need to define a custom rule class which inherits from `tornasole.rules.Rule` class.\n",
    "You need to provide Sagemaker the S3 location of the file which defines your custom rule classes as the value for the field `SourceS3Uri`. Again, you can pass any arguments taken by this rule through the RuntimeConfigurations dictionary. Note that the custom rules can only have arguments which expect a string as the value except the two arguments specifying trials to the Rule. Refer section *Writing a rule* in [DeveloperGuide_Rules.md](../../../../rules/DeveloperGuide_Rules.md) for more details.\n",
    "\n",
    "Here's an example:\n",
    "```\n",
    "rules_specification = [\n",
    "    {\n",
    "      \"RuleName\": \"CustomRule\",\n",
    "      \"SourceS3Uri\": \"s3://weiyou-tornasole-test/rule-script/custom_rule.py\",\n",
    "      \"InstanceType\": \"ml.c5.4xlarge\",\n",
    "      \"VolumeSizeInGB\": 10,\n",
    "      \"RuntimeConfigurations\": {\n",
    "         \"threshold\" : \"0.5\"\n",
    "       }\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CloudWatch Event Integration for Rules\n",
    "When the status of training job or rule execution job change (i.e. starting, failed), TrainingJobStatus [CloudWatch events](https://docs.aws.amazon.com/sagemaker/latest/dg/cloudwatch-events.html) are emitted. Please monitor the rule job statuses by going to CloudWatch->Events->Rule->Monitoring. \n",
    "\n",
    "You can configure a CloudWatch event rule to receive and process these events by setting up a target (Lambda function, SNS) as follows:\n",
    "\n",
    "- Configure the [SageMaker TrainingJobStatus CW event] (https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/EventTypes.html#sagemaker_event_types) to include rule job statuses associated with the training job\n",
    "- Configure the CW event to be emitted when a RuleStatus changes\n",
    "- Create a CloudWatch event rule that monitors the Training Job customer started\n",
    "-  Set a Target (Lambda funtion, SQS) for the CloudWatch event rule that processes the event, and triggers an alarm for the customer based on the RuleStatus. \n",
    "\n",
    "Refer [this page](https://docs.aws.amazon.com/sagemaker/latest/dg/cloudwatch-events.html) for more details. \n",
    "\n",
    "You can see in the response to `describe_rule_execution_jobs()` above, the details about the cloudwatch event that was emitted due to rule success/failure. It would look like the following. \n",
    "> Created CW event Rule: arn:aws:events:us-east-2:072677473360:rule/RuleEvaluationConditionMetRule-tornasole-simple-demo-VanishingGr  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
