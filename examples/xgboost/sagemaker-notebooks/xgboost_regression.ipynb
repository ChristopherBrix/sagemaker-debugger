{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging SageMaker XGBoost Training Jobs with Tornasole\n",
    "\n",
    "\n",
    "This notebook uses the [Abalone data](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html) to demonstrate a regression task using Tornasole with XGBoost. For a classification problem, see [xgboost_classification.ipynb](xgboost_classification.ipynb).\n",
    "\n",
    "## Overview\n",
    "\n",
    "Tornasole is a new capability of Amazon SageMaker that allows debugging machine learning training. \n",
    "Tornasole helps you to monitor your training in near real time using rules and would provide you\n",
    "alerts, once it has detected inconsistency in training. \n",
    "\n",
    "Using Tornasole is a two step process: Saving tensors and Analysis.\n",
    "Let's look at each one of them closely.\n",
    "\n",
    "### Saving tensors (and scalars)\n",
    "\n",
    "In deep learning algorithms, tensors define the state of the training job\n",
    "at any particular instant in its lifecycle.\n",
    "Tornasole exposes a library which allows you to capture these tensors and\n",
    "save them for analysis.\n",
    "Although XGBoost is not a deep learning algorithm, Tornasole is highly customizable\n",
    "and can help provide interpretability by saving insightful metrics, such as\n",
    "performance metrics or feature importances, at different frequencies.\n",
    "Refer to [DeveloperGuide_XGBoost](../DeveloperGuide_XG.md) for details on how to\n",
    "save the metrics you want.\n",
    "\n",
    "### Analysis\n",
    "\n",
    "Analysis of the tensors emitted is captured by the Tornasole concept called ***Rules***.\n",
    "On a very broad level, a rule is a python code used to detect certain conditions during training.\n",
    "Some of the conditions that a data scientist training an algorithm may care about are\n",
    "monitoring for gradients getting too large or too small, detecting overfitting, and so on.\n",
    "Tornasole will come pre-packaged with certain rules.\n",
    "Users can write their own rules using the Tornasole APIs.\n",
    "You can also analyze raw tensor data outside of the Rules construct in say, a Sagemaker notebook,\n",
    "using Tornasole's full set of APIs. \n",
    "Please refer [DeveloperGuide_Rules](../../../rules/DeveloperGuide_Rules.md) for more details about analysis.\n",
    "\n",
    "This example guides you through installation of the required components for emitting tensors in a \n",
    "SageMaker training job and applying a rule over the tensors to monitor the live status of the job. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also install the required tools which will allow emission of tensors (saving tensors) and application of rules to analyze them. This is only for the purposes of this private beta. Once we do this, we will be ready to use Tornasole.\n",
    "\n",
    "You'll probably have to restart this notebook after running the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws s3 sync s3://tornasole-external-preview-use1/sdk/ ~/SageMaker/tornasole-preview-sdk/\n",
    "! pip3 -q install ~/SageMaker/tornasole-preview-sdk/ts-binaries/tornasole_xgboost/py3/latest/tornasole-* --user\n",
    "! chmod +x ~/SageMaker/tornasole-preview-sdk/installer.sh && ~/SageMaker/tornasole-preview-sdk/installer.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you running this notebook for the first time, please wait for the above setup to complete and restart the notebook by selecting *Kernel -> Restart Kernel* before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have built SageMaker XGBoost containers with Tornasole. You can use them from ECR from SageMaker. Here are the links to the images. Please use the image from the appropriate region in which you want your jobs to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Below changes the region to be one where this notebook is running\n",
    "REGION = boto3.Session().region_name\n",
    "ROLE = get_execution_role()\n",
    "os.environ[\"AWS_REGION\"] = REGION\n",
    "\n",
    "TAG = \"latest\"\n",
    "docker_image_name = \"072677473360.dkr.ecr.{}.amazonaws.com/tornasole-preprod-xgboost-0.90-cpu:{}\".format(REGION, TAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training XGBoost models in SageMaker with Tornasole\n",
    "\n",
    "### SageMaker XGBoost as a framwork\n",
    "\n",
    "We'll train a few XGBoost models in this notebook with Tornasole enabled and monitor the training jobs with Tornasole Rules. This will be done using SageMaker XGBoost 0.90 Container as a framework. The [XGBoost algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) can be used as a built-in algorithm or as a framework such TensorFlow. Using XGBoost as a framework provides more flexible than using it as a built-in algorithm as it enables more advanced scenarios that allow pre-processing and post-processing scripts to be incorporated into your training script.\n",
    "\n",
    "Let us first train a simple example training script [xgboost_abalone_basic_hook_demo.py](../scripts/xgboost_abalone_basic_hook_demo.py) with XGBoost enabled in SageMaker using the SageMaker Estimator API, along with a LossNotDecreasing Rule to monitor the training job in realtime. A Tornasole Rule is essentially python code which analyzes tensors saved by tornasole and validates some condition. LossNotDecreasing rule is a first party (1P) rule provided by Tornasole. For other 1P rules that can be used in XGBoost, refer to [FirstPartyRules.md](../../../rules/FirstPartyRules.md)\n",
    "\n",
    "During training, Tornasole will capture tensors as specified in its configuration and LossNotDecreasing Rule job will monitor whether you are running into a situation where loss is not going down. The rule will emit a cloudwatch event if it finds that the performance metrics are not decreasing during training.\n",
    "\n",
    "### Enabling Tornasole in the script\n",
    "\n",
    "You can see in the script that we have made a couple of simple changes to enable Tornasole. We created a TornasoleHook which we pass as a callback function when creating a Booster. We passed a SaveConfig object telling the hook to save the evaluation metrics, feature importances, and SHAP values at regular intervals. Note that Tornasole is highly configurable, you can choose exactly what to save. The changes are described in a bit more detail below after we train this example as well as in even more detail in our [Developer Guide for XGBoost](../DeveloperGuide_XG.md). \n",
    "\n",
    "```python\n",
    "from tornasole.xgboost import TornasoleHook, SaveConfig\n",
    "\n",
    "save_config = SaveConfig(save_interval=frequency)\n",
    "hook = TornasoleHook(save_config=save_config)\n",
    "\n",
    "bst = xgboost.train(\n",
    "    ...\n",
    "    callbacks=[hook]\n",
    ")\n",
    "```\n",
    "\n",
    "### XGBoost for Regression\n",
    "\n",
    "We use the [Abalone data](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html) originally from the [UCI data repository](https://archive.ics.uci.edu/ml/datasets/abalone). More details about the original dataset can be found [here](https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.names).  In the libsvm converted [version](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html), the nominal feature (Male/Female/Infant) has been converted into a real valued feature. Age of abalone is to be predicted from eight physical measurements.\n",
    "\n",
    "Refer to [XGBoost for Regression](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/introduction_to_amazon_algorithms/xgboost_abalone)\n",
    "for an example of using regression from Amazon SageMaker's implementation of\n",
    "[XGBoost](https://github.com/dmlc/xgboost).\n",
    "\n",
    "Just a quick reminder if you are not familiar with script mode in SageMaker. You can pass command line arguments taken by your training script with a hyperparameter dictionary which gets passed to the SageMaker XGBoost Estimator class. You can see this in the examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point_script = \"../scripts/xgboost_abalone_basic_hook_demo.py\"\n",
    "\n",
    "hyperparameters={\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"silent\": \"0\",\n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"num_round\": \"50\",\n",
    "    \"tornasole_frequency\": \"2\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.xgboost import XGBoost\n",
    "\n",
    "estimator = XGBoost(\n",
    "    image_name=docker_image_name,\n",
    "    base_job_name=\"demo-tornasole-xgboost\",\n",
    "    entry_point=entry_point_script,\n",
    "    hyperparameters=hyperparameters,\n",
    "    train_instance_type=\"ml.m4.4xlarge\",\n",
    "    train_instance_count=1,\n",
    "    framework_version=\"0.90-1\",\n",
    "    py_version=\"py3\",\n",
    "    role=ROLE,\n",
    "    \n",
    "    # These are Tornasole specific parameters, \n",
    "    # debug=True means rule specified in rules_specification \n",
    "    # will run as rule job. \n",
    "    # Below, we specify to run the first party rule LossNotDecreasing\n",
    "    # on a ml.c5.4xlarge instance\n",
    "    debug=True,\n",
    "    rules_specification=[\n",
    "        {\n",
    "        \"RuleName\": \"LossNotDecreasing\",\n",
    "        \"InstanceType\": \"ml.c5.4xlarge\",\n",
    "        \"RuntimeConfigurations\": {\n",
    "            \"use_losses_collection\": \"False\",\n",
    "            \"tensor_regex\": \"train-rmse,validation-rmse\",\n",
    "            \"num_steps\" : \"10\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Note that Tornasole is only supported for `py_version='py3'` currently.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a fire and forget event.\n",
    "# By setting wait=False, we just submit the job to run in the background.\n",
    "# In the background SageMaker will spin off 1 training job and 1 rule job for you.\n",
    "# Please follow this notebook to see status of the training job and the rule job.\n",
    "estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "As a result of the above command, SageMaker will spin off 1 training job and 1 rule job for you - the first one being the job which produces the tensors to be analyzed and the second one, which analyzes the tensors to check if `train-rmse` and `validation-rmse` are not decreasing at any point during training.\n",
    "\n",
    "### Describing the training job\n",
    "We can check the status of the training job by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below command will give the status of training job\n",
    "# Note: In the output of below command you will see DebugConfig parameter \n",
    "job_name = estimator.latest_training_job.name\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "description = client.describe_training_job(TrainingJobName=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The status of the training job can be seen below\n",
    "description[\"TrainingJobStatus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your training job is started SageMaker will spin up a rule execution job to run the LossNotDecreasing rule.\n",
    "\n",
    "### Tornasole specific parameters in the description\n",
    "**DebugConfig** parameter has details about Tornasole related configuration. The key parameters to look for below are\n",
    "\n",
    "*S3OutputPath* : This is the path where output tensors from tornasole is getting saved.  \n",
    "*RuleConfig*' : This parameter tells about the rule config parameter that was passed when creating the trainning job. In this you should be able to see details of the rule that ran for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description[\"DebugConfig\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the status of the Rule Execution Job\n",
    "To get the rule execution job that SageMaker started for you, run the command below and it shows you the `RuleName`, `RuleStatus`, `FailureReason` if any, and `RuleExecutionJobArn`. If the tensors meets a rule evaluation condition, the rule execution job throws a client error with `FailureReason: RuleEvaluationConditionMet`. These details are also available as part of the response `description` above under: `description['RuleMonitoringStatuses']`\n",
    "\n",
    "\n",
    "The logs of the training job are available in the Cloudwatch Logstream `/aws/sagemaker/TrainingJobs` with `RuleExecutionJobArn`. \n",
    "\n",
    "You will see that once the rule execution job starts, that it identifies the loss not decreasing situation in the training job, raises the `RuleEvaluationConditionMet` exception and ends the job. \n",
    "\n",
    "**Note that the next cell blocks until the rule execution job ends. You can stop it at any point to proceed to the rest of the notebook. Once it says RuleStatus is Started, and shows the `RuleExecutionJobArn`, you can look at the status of the rule being monitored. At that point, we can also look at the logs as shown in the next cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.describe_rule_execution_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check logs of the rule execution jobs\n",
    "\n",
    "If you want to access the logs of a particular rule job name, you can do the following. First, you need to get the rule job name (`RuleExecutionJobArn` field from the training job description). Note that this is only available after the rule job reaches Started stage. Hence the next cell waits till the job name is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "rule_descr = client.describe_training_job(TrainingJobName=job_name)[\"RuleMonitoringStatuses\"]\n",
    "print(\"Waiting for rule execution job to start\")\n",
    "while \"RuleExecutionJobArn\" not in rule_descr[0]:\n",
    "    time.sleep(5)\n",
    "    rule_descr = client.describe_training_job(TrainingJobName=job_name)[\"RuleMonitoringStatuses\"]\n",
    "\n",
    "rule_job_arn = rule_descr[0][\"RuleExecutionJobArn\"]\n",
    "print(\"Rule execution job has started. The job ARN is {}\".format(rule_job_arn))\n",
    "rule_job_name = rule_job_arn.split('/')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can attach to this job to see its logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "loss_not_decreasing = Estimator.attach(rule_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receive a CloudWatch Event for Rules\n",
    "When the status of training job or rule execution job change (i.e. starting, failed), TrainingJobStatus [CloudWatch events](https://docs.aws.amazon.com/sagemaker/latest/dg/cloudwatch-events.html) are emitted.  More details on this, see [below](#CloudWatch-Event-Integration-for-Rules). \n",
    "\n",
    "\n",
    "### Making this a good run\n",
    "\n",
    "In above example, we saw how a LossNotDecreasing Rule was run which analyzed the performance metrics when training was running and produced an alert in form of cloudwatch event.\n",
    "\n",
    "You can go back and change the hyperparameters passed to the estimator to `hyperparameters` and start a new training job (e.g., use a smaller learning rate `eta=0.05`). You will see that the LossNotDecreasing rule is not fired in that case as both `train-rmse` and `validation-rmse` keep decreasing steadily throughout the entire training duration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis - Manual\n",
    "\n",
    "Now that we have trained the system we can analyze the data. Here we focus on after-the-fact analysis.\n",
    "\n",
    "We import a basic analysis library, which defines a concept of `Trial` that represents a single training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.parse import urlparse\n",
    "from tornasole.trials import create_trial\n",
    "\n",
    "s3_output_path = description[\"DebugConfig\"][\"DebugHookConfig\"][\"S3OutputPath\"]\n",
    "trial = create_trial(s3_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list all the tensors we know something about. Each one of these names is the name of a tensor - the name is a combination of the feature name (which, in these cases, is auto-assigned by XGBoost) and whether it's an evaluation metric, feature importance, or SHAP value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial.tensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each tensor we can ask for which steps we have data - in this case, every 2 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(trial.tensor(\"train-rmse\").steps()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain each tensor at each step as a `numpy` array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(trial.tensor(\"train-rmse\").value(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance metrics\n",
    "\n",
    "We can also create a simple function that visualizes the training and validation errors\n",
    "as the training progresses.\n",
    "We expect each gradient to get smaller over time, as the system converges to a good solution.\n",
    "Now, remember that this is an interactive analysis - we are showing these tensors to give an idea of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define a function that, for the given tensor name, walks through all \n",
    "# the iterations for which we have data and fetches the value.\n",
    "# Returns the set of steps and the values\n",
    "def get_data(trial, tname):\n",
    "    tensor = trial.tensor(tname)\n",
    "    steps = tensor.steps()\n",
    "    vals = [tensor.value(s) for s in steps]\n",
    "    return steps, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_plot = [\"train-rmse\", \"validation-rmse\"]\n",
    "for metric in metrics_to_plot:\n",
    "    steps, data = get_data(trial, metric)\n",
    "    plt.plot(steps, data, label=metric)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Root mean squred error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importances\n",
    "\n",
    "We can also visualize the feature importances as determined by\n",
    "[xgboost.get_fscore()](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.Booster.get_fscore).\n",
    "Note that feature importances with zero values are not included here\n",
    "(which means that those features were not used in any split conditons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_collections(trial, collection_name, ylabel=''):\n",
    "    \n",
    "    plt.figure(\n",
    "        num=1, figsize=(8, 8), dpi=80,\n",
    "        facecolor='w', edgecolor='k')\n",
    "\n",
    "    features = trial.collection(collection_name).tensor_names\n",
    "\n",
    "    for feature in sorted(features):\n",
    "        steps, data = get_data(trial, feature)\n",
    "        label = feature.replace('/' + collection_name, '')\n",
    "        plt.plot(steps, data, label=label)\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.04,1), loc='upper left')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_collections(trial, \"feature_importance\", \"Feature importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP\n",
    "\n",
    "[SHAP](https://github.com/slundberg/shap) (SHapley Additive exPlanations) is\n",
    "another approach to explain the output of machine learning models.\n",
    "SHAP values represent a feature's contribution to a change in the model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_collections(trial, \"average_shap\", \"SHAP values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have an example at the end of this notebook that demonstrates how to use a custom rule in Tornasole. Before moving further, let's take some detailed look at Tornasole, some of which were touched upon above.\n",
    "\n",
    "\n",
    "## Enabling Tornasole in the training script\n",
    "\n",
    "The first step to using Tornasole is to save tensors from the training job. The containers we provide in SageMaker come with Tornasole library installed, which needs to be used to enable Tornasole in your training script.\n",
    "\n",
    "To enable Tornasole in the training script, you need to create and pass TornasoleHook, a construct Tornasole exposes to save tensors. Here's how you will need to modify your training script.\n",
    "\n",
    "First, you need to import `tornasole.xgboost`. \n",
    "```\n",
    "import tornasole\n",
    "import tornasole.xgboost as tx\n",
    "```\n",
    "Then create the TornasoleHook by specifying what you want to save and when you want to save them.\n",
    "```\n",
    "hook = tx.TornasoleHook(include_collections=['metric','feature_importance'],\n",
    "                        save_config=tornasole.SaveConfig(save_interval=5))\n",
    "```\n",
    "Now pass this hook as a callback function to the Booster object's train method.\n",
    "```\n",
    "import xgboost\n",
    "\n",
    "bst = xgboost.train(..., callbacks=[hook])\n",
    "```\n",
    "\n",
    "Refer to our example script [xgboost_abalone_basic_hook_demo.py](../scripts/xgboost_abalone_basic_hook_demo.py) for examples of using Tornasole with the XGBoost interface.\n",
    "\n",
    "Refer [DeveloperGuide_XGBoost.md](../DeveloperGuide_XG.md) for more details on the APIs Tornasole provides to help you save tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enabling Tornasole with SageMaker\n",
    "\n",
    "#### Storage\n",
    "The tensors saved by Tornasole are, by default, stored in the S3 output path of the training job, under the folder **`/tensors-<job name>`**. This is done to ensure that we don't end up accidentally overwriting the tensors from a training job with the others. Rules evaluation require separation of the tensors paths to be evaluated correctly.\n",
    "\n",
    "If you don't provide an S3 output path to the estimator, SageMaker creates one for you as: **`s3://sagemaker-<region>-<account_id>/`**\n",
    "\n",
    "This path is used to create a Tornasole Trial taken by Rules (see below).\n",
    "\n",
    "#### New Parameters \n",
    "The new parameters in Sagemaker Estimator to look out for are\n",
    "\n",
    "- `debug`: (bool)\n",
    "This indicates that debugging should be enabled for the training job. \n",
    "Setting this as `True` would make Tornasole available for use with the job\n",
    "\n",
    "- `rules_specification`: (list[*dict*])\n",
    "You can specify any number of rules to monitor your SageMaker training job. This parameter takes a list of python dictionaries, one for each rule you want to enable. Each `dict` is of the following form:\n",
    "```\n",
    "{\n",
    "    \"RuleName\": <str>       \n",
    "        # The name of the class implementing the Tornasole Rule interface. (required)\n",
    "\n",
    "    \"SourceS3Uri\": <str>    \n",
    "        # S3 URI of the rule script containing the class in 'RuleName'. \n",
    "        # This is not required if you want to use one of the\n",
    "        # First Party rules provided to you by Amazon. \n",
    "        # In such a case you can leave it empty or not pass it. \n",
    "        # If you want to run a custom rule \n",
    "        # defined by you, you will need to define the custom rule class in a python \n",
    "        # file and provide it to SageMaker as a S3 URI. \n",
    "        # SageMaker will fetch this file and try to look for the rule class \n",
    "        # identified by RuleName in this file.\n",
    "    \n",
    "    \"InstanceType\": <str>   \n",
    "        # The ML instance type which should be used to run the rule evaluation job\n",
    "        \n",
    "    \"VolumeSizeInGB\": <int> \n",
    "        # The volume size to store the runtime artifacts from the rule evaluation \n",
    "        \n",
    "    \"RuntimeConfigurations\": {\n",
    "        # Map defining the parameters required to instantiate the Rule class and\n",
    "        # parameters regarding invokation of the rule (start-step and end-step)\n",
    "        # This can be any parameter taken by the rule. \n",
    "        # Every value here needs to be a string. \n",
    "        # So when you write custom rules, ensure that you can parse each argument \n",
    "        # from a string.\n",
    "        #\n",
    "        # PARAMS CAN BE\n",
    "        #\n",
    "        # STANDARD PARAMS FOR RULE EXECUTION\n",
    "        # \"start-step\": <str>\n",
    "        # \"end-step\": <str>\n",
    "        # \"other-trials-paths\": <str> (';' separated list of s3 paths as a string)\n",
    "        # \"logging-level\": <str> (can be one of \"CRITICAL\", \"FATAL\", \"ERROR\", \n",
    "        #                         \"WARNING\", \"WARN\", \"DEBUG\", \"NOTSET\")\n",
    "        #\n",
    "        # ANY OTHER PARAMETER TAKEN BY THE RULE\n",
    "        # \"parameter\" : <str>\n",
    "        # <str>: <str>\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules\n",
    "Rules are the medium by which Tornasole executes a certain piece of code regularly on different steps of the job.\n",
    "They can be used to assert certain conditions during training, and raise Cloudwatch Events based on them that you can\n",
    "use to process in any way you like. \n",
    "\n",
    "Tornasole comes with a set of **First Party rules** (1P rules).\n",
    "You can also write your own rules looking at these 1P rules for inspiration. \n",
    "Refer [DeveloperGuide_Rules.md](../../../rules/DeveloperGuide_Rules.md) for more on the APIs you can use to write your own rules as well as descriptions for the 1P rules that we provide. \n",
    " \n",
    "Here we will talk about how to use Sagemaker to evalute these rules on the training jobs.\n",
    "\n",
    "\n",
    "##### 1P Rule \n",
    "If you want to use a 1P rule. Specify the RuleName field with the 1P RuleName, and the rule will be automatically applied. You can pass any parameters accepted by the rule as part of the RuntimeConfigurations dictionary. Rules constructor take trial as parameter.  \n",
    "A Trial in Tornasole's context refers to a training job. It is identified by the path where the saved tensors for the job are stored.  \n",
    "A rule takes a `base_trial` which refers to the job whose run invokes the rule execution. \n",
    "\n",
    "**Note:** A rule can be written to compare & analyze tensors across training jobs. A rule which needs to compare tensors across trials can be run by passing the argument `other_trials`. The argument `base_trial` will automatically be set by SageMaker when executing the rule. The parameter `other_trials` (if taken by the rule) can be passed by passing `other-trials-paths` in the RuntimeConfigurations dictionary. The value for this argument should be `;` separated list of S3 output paths where the tensors for those trials are stored.\n",
    "\n",
    "Here's a example of a complex configuration for the SimilarAcrossRuns (which accepts one other trial and a regex pattern) where we ask for the rule to be invoked for the steps between 10 and 100.\n",
    "\n",
    "``` \n",
    "rules_specification = [ \n",
    "    {\n",
    "      \"RuleName\": \"SimilarAcrossRuns\",\n",
    "      \"InstanceType\": \"ml.c5.4xlarge\",\n",
    "      \"VolumeSizeInGB\": 10,\n",
    "      \"RuntimeConfigurations\": {\n",
    "         \"other_trials\": \"s3://sagemaker-<region>-<account_id>/past-job\",\n",
    "         \"include_regex\": \".*\",\n",
    "         \"start-step\": \"10\",\n",
    "         \"end-step\": \"100\"\n",
    "       }\n",
    "    }\n",
    "]\n",
    "```\n",
    "List of 1P rules and details about the rules can be found in *First party rules* section in [DeveloperGuide_Rules.md](../../../rules/DeveloperGuide_Rules.md)  \n",
    "\n",
    "\n",
    "##### Custom rule\n",
    "In this case you need to define a custom rule class which inherits from `tornasole.rules.Rule` class.\n",
    "You need to provide Sagemaker the S3 location of the file which defines your custom rule classes as the value for the field `SourceS3Uri`. Again, you can pass any arguments taken by this rule through the RuntimeConfigurations dictionary. Note that the custom rules can only have arguments which expect a string as the value except the two arguments specifying trials to the Rule. Refer section *Writing a rule* in [DeveloperGuide_Rules.md](../../../rules/DeveloperGuide_Rules.md) for more details.\n",
    "\n",
    "Here's an example:\n",
    "```\n",
    "rules_specification = [\n",
    "    {\n",
    "      \"RuleName\": \"CustomRule\",\n",
    "      \"SourceS3Uri\": \"s3://tornasole-test/rule-script/custom_rule.py\",\n",
    "      \"InstanceType\": \"ml.c5.4xlarge\",\n",
    "      \"VolumeSizeInGB\": 10,\n",
    "      \"RuntimeConfigurations\": {\n",
    "         \"threshold\" : \"0.5\"\n",
    "       }\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CloudWatch Event Integration for Rules\n",
    "When the status of training job or rule execution job change (i.e. starting, failed), TrainingJobStatus [CloudWatch events](https://docs.aws.amazon.com/sagemaker/latest/dg/cloudwatch-events.html) are emitted.\n",
    "\n",
    "After GA, you can configure a CloudWatch event rule to receive and process these events by setting up a target (Lambda function, SNS) as follows:\n",
    "\n",
    "- The SageMaker TrainingJobStatus CW event (https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/EventTypes.html#sagemaker_event_types) will include rule job statuses associated with the training job\n",
    "- A CW event will be emitted when a RuleStatus changes\n",
    "- Customer can create a CloudWatch event rule that monitors the Training Job customer started\n",
    "- Customer can set a Target (Lambda funtion, SQS) for the CloudWatch event rule that processes the event, and triggers an alarm for the customer based on the RuleStatus. \n",
    "\n",
    "Refer [this page](https://docs.aws.amazon.com/sagemaker/latest/dg/cloudwatch-events.html) for more details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom rule: Single Feature Importance\n",
    "\n",
    "In this case you need to define a custom rule class which inherits from `tornasole.rules.Rule` class.\n",
    "You need to provide Sagemaker the S3 location of the file which defines your custom rule classes as the value for the field `SourceS3Uri`.\n",
    "Again, you can pass any arguments taken by this rule through the RuntimeConfigurations dictionary. \n",
    "Note that the custom rules can only have arguments which expect a string as the value except the two arguments \n",
    "specifying trials to the Rule. Refer [DeveloperGuide_Rules.md](../../../rules/DeveloperGuide_Rules.md) for more.\n",
    "\n",
    "In the following code cell, we write a custom rule named `SingleFeatureImportance`\n",
    "that checks if any feature importance in a given collection goes out of the\n",
    "specified range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/custom_feature_importance_rule.py\n",
    "\n",
    "from tornasole.rules.rule import Rule\n",
    "\n",
    "class SingleFeatureImportance(Rule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            base_trial,\n",
    "            collection_name,\n",
    "            num_features=None,\n",
    "            min_importance_ratio=0,\n",
    "            max_importance_ratio=1\n",
    "            ):\n",
    "        \"\"\"\n",
    "        This rule checks the following statement:\n",
    "        - In a given collection, each feature should have importance\n",
    "          satisfying the following conditions:\n",
    "          a) min_importance*(1/feature_no) <= feature importance\n",
    "          b) feature_importance <= max_importance*(1/feature_no)\n",
    "\n",
    "        :param base_trial: the trial whose execution will invoke the rule\n",
    "        :param min_importance_ratio: the minimum allowed importance (as a proportion of 1/feature_no)\n",
    "        :param max_importance_ratio: the maximum allowed importance (as a proportion of 1/feature_no)\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.tensor_names = base_trial.collection(self.collection_name).tensor_names\n",
    "        self.num_features = len(self.tensor_names) if num_features is None else int(num_features)\n",
    "        self.min_importance_ratio = float(min_importance_ratio)\n",
    "        self.max_importance_ratio = float(max_importance_ratio)\n",
    "\n",
    "        super().__init__(base_trial, other_trials=None)\n",
    "        \n",
    "        self.logger.info(\"FeatureImportance rule created.\")\n",
    "\n",
    "    def invoke_at_step(self, step, **kwargs):\n",
    "        \n",
    "        min_importance = self.min_importance_ratio * (1 / self.num_features)\n",
    "        max_importance = self.max_importance_ratio * (1 / self.num_features)\n",
    "\n",
    "        failed = []\n",
    "\n",
    "        for name in self.tensor_names:\n",
    "            \n",
    "            if step not in self.base_trial.tensor(name).steps():\n",
    "                importance = 0\n",
    "            else:\n",
    "                importance = self.base_trial.tensor(name).value(step)\n",
    "\n",
    "            if importance < min_importance:\n",
    "                self.logger.debug(f\"Step {step} feature {name} has importance {importance}<{min_importance}\")\n",
    "                failed.append((name, importance))\n",
    "            elif max_importance < importance:\n",
    "                self.logger.debug(f\"Step {step} feature {name} has importance {importance}>{max_importance}\")\n",
    "                failed.append((name, importance))\n",
    "\n",
    "        self.logger.info(failed)\n",
    "        self.logger.info(f\"Step {step} had {len(failed)} features with out-of-band values\")\n",
    "\n",
    "        return True if failed else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to upload this to a bucket in the same region where we want to run the job. We have chosen a default bucket below. Please change it to the bucket you want. We will now create this bucket if it does not exist, and upload this file. We will then specify this path when starting the job as `SourceS3Uri`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCOUNT_ID = boto3.client('sts').get_caller_identity().get('Account')\n",
    "BUCKET = f'tornasole-resources-{ACCOUNT_ID}-{REGION}'\n",
    "\n",
    "CUSTOM_RULE_PATH = '/tmp/custom_feature_importance_rule.py'\n",
    "\n",
    "PREFIX = os.path.join('rules', os.path.basename(CUSTOM_RULE_PATH))\n",
    "\n",
    "import os\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(BUCKET)\n",
    "if not bucket.creation_date:\n",
    "    s3.create_bucket(Bucket=BUCKET, CreateBucketConfiguration={'LocationConstraint': REGION})\n",
    "s3.Object(BUCKET, PREFIX).put(Body=open(CUSTOM_RULE_PATH, 'rb'))\n",
    "SOURCE_S3_URI = f's3://{BUCKET}/{PREFIX}'\n",
    "print(f\"Upload to {SOURCE_S3_URI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(\n",
    "    base_job_name=\"xgboost-tornasole-feature-importance\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    image_name=docker_image_name,\n",
    "    role=ROLE,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.m4.4xlarge\",\n",
    "    debug=True,\n",
    "    rules_specification = [\n",
    "        {\n",
    "        \"RuleName\": \"SingleFeatureImportance\",\n",
    "        \"SourceS3Uri\": SOURCE_S3_URI,\n",
    "        \"InstanceType\": \"ml.c5.xlarge\",\n",
    "        \"VolumeSizeInGB\": 10,\n",
    "        \"RuntimeConfigurations\": {\n",
    "            \"collection_name\": \"average_shap\",\n",
    "            \"num_features\": \"8\",\n",
    "            \"min_importance_ratio\": \"0.0\",\n",
    "            \"max_importance_ratio\": \"2.0\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(wait=False)\n",
    "\n",
    "job_name = estimator.latest_training_job.name\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "description = client.describe_training_job(TrainingJobName=job_name)\n",
    "\n",
    "description[\"TrainingJobStatus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description[\"DebugConfig\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can visually verify in the [Data Analysis](#Data-Analysis---Manual) section above,\n",
    "the SHAP value of feature will become significant, and we expect our rule to throw a\n",
    "`RuleEvaluationConditionMet` exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.describe_rule_execution_jobs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
