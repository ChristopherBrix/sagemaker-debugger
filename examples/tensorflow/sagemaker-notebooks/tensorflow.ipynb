{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging SageMaker Training Jobs with Tornasole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tornasole is a new capability of Amazon SageMaker that allows debugging machine learning training. \n",
    "It lets you go beyond just looking at scalars like losses and accuracies during training and gives \n",
    "you full visibility into all tensors 'flowing through the graph' during training.\n",
    "\n",
    "Using Tornasole is a two step process: Saving tensors and Analysis. Let's look at each one of them closely.\n",
    "\n",
    "### Saving tensors\n",
    "\n",
    "Tensors define the state of the training job at any particular instant in its lifecycle. Tornasole exposes a library which allows you to capture these tensors and save them for analysis. Tornasole is highly customizable to save the tesnsors you want at different frequencies. Refer [DeveloperGuide_TensorFlow](../../DeveloperGuide_TF.md) for details on how to save the tensors you want to save.\n",
    "\n",
    "### Analysis\n",
    "\n",
    "Analyses of the tensors emitted is captured by the Tornasole concept called ***Rules***. On a very broad level, \n",
    "A Rule is a python code used to detect certain conditions during training. Some of the conditions that a data scientist training a deep learning model may care about are monitoring for gradients getting too large or too small, detecting overfitting, and so on.\n",
    "Tornasole will come pre-packaged with certain rules. Users can write their own rules using the Tornasole APIs.\n",
    "You can also analyze raw tensor data outside of the Rules construct in say, a Sagemaker notebook, using Tornasole's full set of APIs. \n",
    "Please refer [DeveloperGuide_Rules](../../../rules/DeveloperGuide_Rules.md) for more details about analysis.\n",
    "\n",
    "This example guides you through installation of the required components for emitting tensors in a \n",
    "SageMaker training job and applying a rule over the tensors to monitor the live status of the job. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "As a first step, we'll do the installation of required tools which will allow emission of tensors (saving tensors) and application of rules to analyze them. This is only for the purposes of this private beta. Once we do this, we will be ready to use Tornasole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync s3://tornasole-external-preview-use1/ ~/tornasole-preview\n",
    "!pip -q install ~/tornasole-preview/sdk/sagemaker-tornasole-latest.tar.gz\n",
    "!aws configure add-model --service-model file://`echo ~/tornasole-preview/sdk/sagemaker-tornasole.json` --service-name sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable Tornasole in the training script\n",
    "\n",
    "The first step to using Tornasole is to save tensors from the training job. The containers we provide in SageMaker come with Tornasole library installed, which needs to be used to enable Tornasole in your training script. We currently support two interfaces for training in TensorFlow: `tf.Session` and `tf.Estimator`. \n",
    "\n",
    "Please note: **Keras** support is Work in Progress. Please stay tuned! We will also support **Eager** mode in the future. Tornasole also currently only works for single process training. We will support distributed training very soon. \n",
    "\n",
    "### TF Session based training\n",
    "When training using this interface you need to create a [MonitoredSession](https://www.tensorflow.org/api_docs/python/tf/train/MonitoredSession) to use for the job which is configured with TornasoleHook, a construct Tornasole exposes to save tensors from the job. Here's how you will need to modify your training script.\n",
    "\n",
    "First, you need to import `tornasole.tensorflow`. \n",
    "```\n",
    "import tornasole.tensorflow as ts \n",
    "```\n",
    "Then create the TornasoleHook by specifying what you want to save and when you want to save them.\n",
    "```\n",
    "hook = ts.TornasoleHook(include_collections=['weights','gradients'],\n",
    "                        save_config=ts.SaveConfig(save_interval=50))\n",
    "```\n",
    "Tornasole has the concept of modes (TRAIN, EVAL, PREDICT) to separate out different modes of the jobs.\n",
    "Set the mode you are running in your job. Every time the mode changes in your job, please set the current mode. This helps you group steps by mode, for easier analysis. Setting the mode is optional but recommended. If you do not specify this, Tornasole saves all steps under a `GLOBAL` mode. \n",
    "```\n",
    "hook.set_mode(ts.modes.TRAIN)\n",
    "```\n",
    "Wrap your optimizer with TornasoleOptimizer so that Tornasole can identify your gradients and automatically provide these tensors as part of the `gradients` collection. Use this new optimizer to minimize your loss during training.\n",
    "```\n",
    "optimizer = ts.TornasoleOptimizer(optimizer)\n",
    "```\n",
    "Create a monitored session with the above hook, and use this for executing your TensorFlow job.\n",
    "```\n",
    "sess = tf.train.MonitoredSession(hooks=[hook])\n",
    "```\n",
    "\n",
    "We have an example script which shows the above [scripts/simple.py](../scripts/simple.py). You will be running this script below.\n",
    "\n",
    "Refer [DeveloperGuide_TensorFlow.md](../DeveloperGuide_TF.md) for more details on the APIs Tornasole provides to help you save tensors.\n",
    "\n",
    "### TF Estimator based training\n",
    "When training using this interface you need to pass TornasoleHook, a construct Tornasole exposes to save tensors, to the train, predict or evaluate functions of your [TensorFlow Estimator](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator/Estimator?hl=en). Here's how you will need to modify your training script.\n",
    "\n",
    "First, you need to import `tornasole.tensorflow`. \n",
    "```\n",
    "import tornasole.tensorflow as ts \n",
    "```\n",
    "Then create the TornasoleHook by specifying what you want to save and when you want to save them.\n",
    "```\n",
    "hook = ts.TornasoleHook(include_collections=['weights','gradients'],\n",
    "                        save_config=ts.SaveConfig(save_interval=50))\n",
    "```\n",
    "Tornasole has the concept of modes (TRAIN, EVAL, PREDICT) to separate out different modes of the jobs.\n",
    "Set the mode you are running in your job. Every time the mode changes in your job, please set the current mode. This helps you group steps by mode, for easier analysis. Setting the mode is optional but recommended. If you do not specify this, Tornasole saves all steps under a `GLOBAL` mode. \n",
    "```\n",
    "hook.set_mode(ts.modes.TRAIN)\n",
    "```\n",
    "Wrap your optimizer with TornasoleOptimizer so that Tornasole can identify your gradients and automatically provide these tensors as part of the `gradients` collection. Use this new optimizer to minimize your loss during training.\n",
    "```\n",
    "opt = ts.TornasoleOptimizer(opt)\n",
    "```\n",
    "Now pass this hook to the estimator object's train, predict or evaluate methods, whichever ones you want to monitor.\n",
    "```\n",
    "classifier = tf.estimator.Estimator(...)\n",
    "\n",
    "classifier.train(input_fn, hooks=[hook])\n",
    "classifier.predict(input_fn, hooks=[hook])\n",
    "classifier.evaluate(input_fn, hooks=[hook])\n",
    "```\n",
    "\n",
    "Refer our example script for [MNIST](../scripts/mnist.py) or [ResNet50 for ImageNet](../scripts/train_imagenet_resnet_hvd.py) for examples of using Tornasole with the Estimator interface. We will show you to how to run these examples in SageMaker below.\n",
    "\n",
    "Refer [DeveloperGuide_TensorFlow.md](../DeveloperGuide_TF.md) for more details on the APIs Tornasole provides to help you save tensors.\n",
    "\n",
    "## SageMaker with Tornasole\n",
    "\n",
    "We'll train a few TensorFlow models in this notebook with Tornasole enabled and monitor the training jobs with Tornasole's Rules. This will be done using SageMaker TensorFlow 1.13.1 Container in Script Mode. Note that Tornasole currently only works with python3, so be sure to set `py_version='py3'` when creating SageMaker Estimator below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storage\n",
    "The tensors saved by Tornasole are, by default, stored in the S3 output path of the training job, under the folder **`/tensors-<job name>`**. This is done to ensure that we don't end up accidentally overwriting the tensors from a training job with the others. Rules evaluation require separation of the tensors paths to be evaluated correctly.\n",
    "\n",
    "If you don't provide an S3 output path to the estimator, SageMaker creates one for you as: **`s3://sagemaker-<region>-<account_id>/`**\n",
    "\n",
    "This path is used to create a Tornasole Trial taken by Rules (see below).\n",
    "\n",
    "#### New Parameters \n",
    "The new parameters in Sagemaker Estimator to look out for are\n",
    "\n",
    "# TODO: mention logging level for rule below\n",
    "\n",
    "- `debug` :(bool)\n",
    "This indicates that debugging should be enabled for the training job. \n",
    "Setting this as `True` would make Tornasole available for use with the job\n",
    "\n",
    "- `rules_specification`: (list[*dict*])\n",
    "You can specify any number of rules to monitor your SageMaker training job. This parameter takes a list of python dictionaries, one for each rule you want to enable. Each `dict` is of the following form:\n",
    "```\n",
    "{\n",
    "    \"RuleName\": <str>       \n",
    "        # The name of the class implementing the Tornasole Rule interface. (required)\n",
    "\n",
    "    \"SourceS3Uri\": <str>    \n",
    "        # S3 URI of the rule script containing the class in 'RuleName'. \n",
    "        # This is not required if you want to use one of the First Party rules provided to you by Amazon. \n",
    "        # In such a case you can leave it empty or not pass it. If you want to run a custom rule \n",
    "        # defined by you, you will need to define the custom rule class in a python \n",
    "        # file and provide it to SageMaker as a S3 URI. \n",
    "        # SageMaker will fetch this file and try to look for the rule class \n",
    "        # identified by RuleName in this file.\n",
    "    \n",
    "    \"InstanceType\": <str>   \n",
    "        # The ML instance type which should be used to run the rule evaluation job\n",
    "        \n",
    "    \"VolumeSizeInGB\": <int> \n",
    "        # The volume size to store the runtime artifacts from the rule evaluation \n",
    "        \n",
    "    \"RuntimeConfigurations\": {\n",
    "        # Map defining the parameters required to instantiate the Rule class and\n",
    "        # parameters regarding invokation of the rule (start-step and end-step)\n",
    "        # This can be any parameter taken by the rule. Every value here needs to be a string. \n",
    "        # So when you write custom rules, ensure that you can parse each argument from a string.\n",
    "        # PARAMS CAN BE\n",
    "        # STANDARD PARAMS FOR RULE EXECUTION\n",
    "        # \"start-step\": <str>\n",
    "        # \"end-step\": <str>\n",
    "        # \"other-trials-paths\": <str> (';' separated list of s3 paths as a string)\n",
    "        # ANY OTHER PARAMETER TAKEN BY THE RULE\n",
    "        # \"parameter\" : <str>\n",
    "        <str>: <str>\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### Inputs\n",
    "Just a quick reminder if you are not familiar with script mode in SageMaker. You can pass command line arguments taken by your training script with a hyperparameter dictionary which gets passed to the SageMaker Estimator class. You can see this in the examples below.\n",
    "\n",
    "### Rules\n",
    "Rules are the medium by which Tornasole executes a certain piece of code regularly on different steps of the job.\n",
    "They can be used to assert certain conditions during training, and raise Cloudwatch Events based on them that you can\n",
    "use to process in any way you like. \n",
    "\n",
    "A Trial in Tornasole's context refers to a training job. It is identified by the path where the saved tensors for the job are stored. A rule takes a `base_trial` which refers to the job whose run invokes the rule execution. A rule can optionally look at other jobs as well, passed using the argument `other_trials`. \n",
    "\n",
    "Tornasole comes with a set of **First Party rules** (1P rules).\n",
    "You can also write your own rules looking at these 1P rules for inspiration. \n",
    "Refer [DeveloperGuide_Rules.md](../../../rules/DeveloperGuide_Rules.md) for more on the APIs you can use to write your own rules as well as descriptions for the 1P rules that we provide. \n",
    " \n",
    "Here we will talk about how to use Sagemaker to evalute these rules on the training jobs.\n",
    "\n",
    "\n",
    "##### 1P Rule \n",
    "If you want to use a 1P rule. Specify the RuleName field with the 1P RuleName, and the rule will be automatically applied. You can pass any parameters accepted by the rule as part of the RuntimeConfigurations dictionary. The argument `base_trial` will automatically be set by SageMaker when executing the rule. The parameter `other_trials` (if taken by the rule) can be passed by passing `other-trials-paths` in the RuntimeConfigurations dictionary. The value for this argument should be `;` separated list of S3 output paths where the tensors for those trials are stored.\n",
    "\n",
    "Here's a example of a complex configuration for the SimilarAcrossRuns (which accepts one other trial and a regex pattern) where we ask for the rule to be invoked for the steps between 10 and 100.\n",
    "\n",
    "``` \n",
    "rules_specification = [ \n",
    "    {\n",
    "      \"RuleName\": \"SimilarAcrossRuns\",\n",
    "      \"InstanceType\": \"ml.c5.4xlarge\",\n",
    "      \"VolumeSizeInGB\": 10,\n",
    "      \"RuntimeConfigurations\": {\n",
    "         \"other_trials\": \"s3://sagemaker-<region>-<account_id>/past-job\",\n",
    "         \"include_regex\": \".*\",\n",
    "         \"start-step\": \"10\",\n",
    "         \"end-step\": \"100\"\n",
    "       }\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "##### Custom rule\n",
    "In this case you need to define a custom rule class which inherits from `tornasole.rules.Rule` class.\n",
    "You need to provide Sagemaker the S3 location of the file which defines your custom rule classes as the value for the field `SourceS3Uri`. Again, you can pass any arguments taken by this rule through the RuntimeConfigurations dictionary. Note that the custom rules can only have arguments which expect a string as the value except the two arguments specifying trials to the Rule. Refer [DeveloperGuide_Rules.md](../../../rules/DeveloperGuide_Rules.md) for more.\n",
    "\n",
    "Here's an example:\n",
    "```\n",
    "rules_specification = [\n",
    "    {\n",
    "      \"RuleName\": \"CustomRule\",\n",
    "      \"SourceS3Uri\": \"s3://weiyou-tornasole-test/rule-script/custom_rule.py\",\n",
    "      \"InstanceType\": \"ml.c5.4xlarge\",\n",
    "      \"VolumeSizeInGB\": 10,\n",
    "      \"RuntimeConfigurations\": {\n",
    "         \"threshold\" : \"0.5\"\n",
    "       }\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "## Training TensorFlow models in SageMaker with Tornasole\n",
    "Now let us see how to train a model in SageMaker using the SageMaker Estimator with Tornasole enabled, along with a rule to monitor the job. First, let us import the required libraries and set the links to docker images that we will use.\n",
    "\n",
    "### Docker Images with Tornasole\n",
    "We have built SageMaker TensorFlow containers with Tornasole. You can use them from ECR from SageMaker. Here are the links to the images. Please change the region below to the region you want your jobs to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "REGION='us-west-2'\n",
    "TAG='latest'\n",
    "\n",
    "gpu_docker_image_name = '072677473360.dkr.ecr.{}.amazonaws.com/tornasole-preprod-tf-1.13.1-gpu:{}'.format(REGION, TAG)\n",
    "cpu_docker_image_name = '072677473360.dkr.ecr.{}.amazonaws.com/tornasole-preprod-tf-1.13.1-cpu:{}'.format(REGION, TAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training a simple Session based example\n",
    "For the purposes of this demonstration let us use a simple script that produces nans during training and monitor the job with the rule ExplodingTensor which checks for this condition. Let us create a bad hyperparameters dictionary which sets bad learning rate and scale parameters taken by the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "simple_entry_point_script = '../scripts/simple.py'\n",
    "simple_hyperparameters = { 'steps': 10000, 'tornasole_frequency': 50 }\n",
    "\n",
    "# copy dict\n",
    "bad_simple_hyperparameters = dict(simple_hyperparameters)\n",
    "bad_simple_hyperparameters.update({ 'lr': 100, 'scale': 100000000000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_simple_estimator = TensorFlow(role=sagemaker.get_execution_role(),\n",
    "                       base_job_name='tornasole-simple-demo',\n",
    "                       train_instance_count=1,\n",
    "                       train_instance_type='ml.m4.xlarge',\n",
    "                       image_name=cpu_docker_image_name,\n",
    "                       entry_point=simple_entry_point_script,\n",
    "                       framework_version='1.13.1',\n",
    "                       py_version='py3',\n",
    "                       script_mode=True,\n",
    "                       hyperparameters=bad_simple_hyperparameters,\n",
    "                       debug=True,\n",
    "                       train_max_run=1800,\n",
    "                       rules_specification=[\n",
    "                           {\n",
    "                              \"RuleName\": \"ExplodingTensor\",\n",
    "                              \"InstanceType\": \"ml.c5.4xlarge\",\n",
    "                              \"RuntimeConfigurations\": {\n",
    "                                 \"only_nan\" : \"True\"\n",
    "                              }\n",
    "                          }\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By setting wait=False, we just submit the job to run in the background\n",
    "sagemaker_simple_estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "As a result of the above command, SageMaker will spin off 2 training jobs for you - the first one being the job which produces the tensors to be analyzed and the second one, which evaluates or analyzes the rule you asked it to in `rules_specification`.\n",
    "\n",
    "### Check the status of the Rule Execution Job\n",
    "To get the rule execution job that SageMaker started for you, run the command below and it shows you the `RuleName`, `RuleStatus`, `FailureReason` if any, and `RuleExecutionJobArn`. If the tensors meets a rule evaluation condition, the rule execution job throws a client error with `FailureReason: RuleEvaluationConditionMet`. You can check the Cloudwatch Logstream `/aws/sagemaker/TrainingJobs` with `RuleExecutionJobArn`.\n",
    "\n",
    "You will see that once the rule execution job starts, that it identifies the exploding tensor situation in the training job, raises the `RuleEvaluationConditionMet` exception and ends the job.\n",
    "\n",
    "You can go back and change the hyperparameters passed to the estimator to `simple_hyperparameters` and start a new training job. You will see that the ExplodingTensor rule is not fired in that case as no tensors go to `nan` with the default good hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_simple_estimator.describe_rule_execution_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Strengthen rule execution section @Ishan\n",
    "\n",
    "### Receive CloudWatch Event For your Jobs\n",
    "When the status of training job or rule execution job change (i.e. starting, failed), TrainingJobStatus [CloudWatch events](https://docs.aws.amazon.com/sagemaker/latest/dg/cloudwatch-events.html) are emitted. You can configure a CloudWatch event rule to receive and process these events by setting up a target (Lambda function, SNS). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Resnet50 on Imagenet with Tornasole\n",
    "Now let us run a more complicated example, let us train ResNet50 on a GPU instance. The script which uses the TensorFlow Estimator interface is available [here](../../scripts/train_imagenet_resnet_hvd.py). It supports various modes of using Tornasole. Please refer to [this document](../../sm_resnet50.md) which summarizes the changes made to this script to save weights, gradients, activations of certain layers etc. You can also save large layers as reductions instead of saving the full tensor. Full details of Tornasole's APIs to save tensors are available in this document [DeveloperGuide_TensorFlow](../../DeveloperGuide_TF.md).\n",
    "\n",
    "The below hyperparameters initialize the weights of the model badly (to a small constant). This results in training proceeding badly with many gradients vanishing. We can monitor the situation using the VanishingGradient rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_script = '../scripts/train_imagenet_resnet_hvd.py'\n",
    "bad_resnet_hyperparameters = {\n",
    "    'enable_tornasole': True,\n",
    "    'tornasole_save_gradients': True,\n",
    "    'tornasole_save_gradients': True,\n",
    "    'tornasole_step_interval' : 100,\n",
    "    'num_epochs': 1,\n",
    "    'constant_initializer': 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_resnet_estimator = TensorFlow(role=sagemaker.get_execution_role(),\n",
    "                  base_job_name='tornasole-demo-resnet',\n",
    "                  train_instance_count=1,\n",
    "                  train_instance_type='ml.p3.2xlarge',\n",
    "                  image_name=gpu_docker_image_name,\n",
    "                  entry_point=resnet_script,\n",
    "                  framework_version='1.13.1',\n",
    "                  py_version='py3',\n",
    "                  script_mode=True,\n",
    "                  hyperparameters=bad_resnet_hyperparameters,\n",
    "                  debug=True,\n",
    "                  train_max_run=1800,\n",
    "                  rules_specification=[\n",
    "                      {\n",
    "                          \"RuleName\": \"VanishingGradient\",\n",
    "                          \"InstanceType\": \"ml.c5.4xlarge\",\n",
    "                      }\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_resnet_estimator.fit(wait=False)\n",
    "sagemaker_resnet_estimator.describe_rule_execution_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MNIST with Estimator interface\n",
    "If you do not want to use GPUs at this point, but want to run a slightly more complicated script than the simple example you saw above, you can train a model on CPU on the MNIST dataset as below. Let us monitor for VanishingGradient in this job. We do not expect this rule to be fired for the below hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_script = '../scripts/mnist.py'\n",
    "mnist_hyperparameters = {'num_epochs': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_mnist_estimator = TensorFlow(role=sagemaker.get_execution_role(),\n",
    "                  base_job_name='tornasole-demo-mnist',\n",
    "                  train_instance_count=1,\n",
    "                  train_instance_type='ml.m4.xlarge',\n",
    "                  image_name=cpu_docker_image_name,\n",
    "                  entry_point=mnist_script,\n",
    "                  framework_version='1.13.1',\n",
    "                  py_version='py3',\n",
    "                  script_mode=True,\n",
    "                  hyperparameters=mnist_hyperparameters,\n",
    "                  debug=True,\n",
    "                  train_max_run=1800,\n",
    "                  rules_specification=[\n",
    "                      {\n",
    "                          \"RuleName\": \"VanishingGradient\",\n",
    "                          \"InstanceType\": \"ml.c5.4xlarge\",\n",
    "                      }\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_mnist_estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait to get status for Rule Execution Jobs...\n",
      "=============================================\n",
      "RuleName: VanishingGradient\n",
      "RuleStatus: NotStarted\n",
      "=============================================\n",
      "Wait to get status for Rule Execution Jobs...\n",
      "=============================================\n",
      "RuleName: VanishingGradient\n",
      "RuleStatus: NotStarted\n",
      "=============================================\n",
      "Wait to get status for Rule Execution Jobs...\n",
      "=============================================\n",
      "RuleName: VanishingGradient\n",
      "RuleStatus: NotStarted\n",
      "=============================================\n",
      "Wait to get status for Rule Execution Jobs...\n",
      "=============================================\n",
      "RuleName: VanishingGradient\n",
      "RuleStatus: NotStarted\n",
      "=============================================\n",
      "Wait to get status for Rule Execution Jobs...\n",
      "=============================================\n",
      "RuleName: VanishingGradient\n",
      "RuleStatus: NotStarted\n",
      "=============================================\n",
      "Wait to get status for Rule Execution Jobs...\n",
      "=============================================\n",
      "RuleName: VanishingGradient\n",
      "RuleStatus: NotStarted\n",
      "=============================================\n",
      "Wait to get status for Rule Execution Jobs...\n",
      "=============================================\n",
      "RuleName: VanishingGradient\n",
      "RuleStatus: NotStarted\n",
      "=============================================\n",
      "Wait to get status for Rule Execution Jobs...\n",
      "=============================================\n",
      "RuleName: VanishingGradient\n",
      "RuleStatus: NotStarted\n",
      "=============================================\n",
      "Wait to get status for Rule Execution Jobs...\n",
      "=============================================\n",
      "RuleName: VanishingGradient\n",
      "RuleStatus: NotStarted\n",
      "=============================================\n",
      "Wait to get status for Rule Execution Jobs...\n",
      "=============================================\n",
      "RuleName: VanishingGradient\n",
      "RuleStatus: NotStarted\n",
      "=============================================\n",
      "Wait to get status for Rule Execution Jobs...\n",
      "=============================================\n",
      "RuleName: VanishingGradient\n",
      "RuleStatus: NotStarted\n",
      "=============================================\n",
      "Wait to get status for Rule Execution Jobs...\n",
      "=============================================\n",
      "RuleName: VanishingGradient\n",
      "RuleStatus: NotStarted\n",
      "=============================================\n",
      "Wait to get status for Rule Execution Jobs...\n",
      "=============================================\n",
      "RuleName: VanishingGradient\n",
      "RuleStatus: NotStarted\n",
      "=============================================\n",
      "Wait to get status for Rule Execution Jobs...\n",
      "=============================================\n",
      "RuleName: VanishingGradient\n",
      "RuleStatus: InProgress\n",
      "RuleExecutionJobArn: arn:aws:sagemaker:us-west-2:072677473360:training-job/vanishinggradient-33e47daec3c768a56aa1df7156bbf153\n",
      "2019-08-23 09:41:53 Starting - Launching requested ML instances...\n",
      "2019-08-23 09:42:58 Starting - Preparing the instances for training......\n",
      "2019-08-23 09:43:53 Downloading - Downloading input data\n",
      "2019-08-23 09:43:53 Training - Downloading the training image.\n",
      "\u001b[31m[2019-08-23 09:44:07.186 ip-10-0-105-42.us-west-2.compute.internal:1 INFO s3_trial.py:27] Loading trial base-trial at path s3://sagemaker-us-west-2-072677473360/tensors-tornasole-demo-mnist-2019-08-23-09-38-13-363\u001b[0m\n",
      "\u001b[31mException during rule execution: unpack requires a buffer of 4 bytes\u001b[0m\n",
      "\u001b[31mTraceback (most recent call last):\n",
      "  File \"train.py\", line 275, in <module>\n",
      "    driver.execute()\n",
      "  File \"train.py\", line 190, in execute\n",
      "    self._create_trials()\n",
      "  File \"train.py\", line 140, in _create_trials\n",
      "    range_steps=(self.start_step, self.end_step))\n",
      "  File \"/usr/local/lib/python3.7/site-packages/tornasole/trials/utils.py\", line 13, in create_trial\n",
      "    prefix_name=prefix_name, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/tornasole/trials/s3_trial.py\", line 35, in __init__\n",
      "    self._load_tensors()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/tornasole/trials/s3_trial.py\", line 38, in _load_tensors\n",
      "    self._read_all_events_file_from_s3()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/tornasole/trials/s3_trial.py\", line 112, in _read_all_events_file_from_s3\n",
      "    self._read_keys()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/tornasole/trials/s3_trial.py\", line 124, in _read_keys\n",
      "    sf = self._read_tensors_from_data(data)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/tornasole/trials/s3_trial.py\", line 146, in _read_tensors_from_data\n",
      "    return list(res)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/tornasole/core/tfrecord/tensor_reader.py\", line 39, in read_tensors\n",
      "    for (step,summ) in self.read_summaries(check=check):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/tornasole/core/tfrecord/tensor_reader.py\", line 61, in read_summaries\n",
      "    for ev in self.read_events(check=check):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/tornasole/core/tfrecord/tensor_reader.py\", line 70, in read_events\n",
      "    rec = self.read_record(check=check)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/tornasole/core/tfrecord/tensor_reader.py\", line 29, in read_record\n",
      "    saved_payload_crc = struct.unpack('I', self._read(4))[0]\u001b[0m\n",
      "\u001b[31mstruct.error: unpack requires a buffer of 4 bytes\u001b[0m\n",
      "\n",
      "2019-08-23 09:44:29 Uploading - Uploading generated training model\n",
      "2019-08-23 09:44:29 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job VanishingGradient-33e47daec3c768a56aa1df7156bbf153: Failed. Reason: InternalServerError: We encountered an internal error. Please try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-419e033e8538>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmnist_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe_rule_execution_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mdescribe_rule_execution_jobs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                             \u001b[0;31m#         cw_rule_arns[rule_name] = cw_rule_arn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                             \u001b[0;31m# Tail logs of rule job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_rule_job_arn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrule_job_arn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrule_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m                             \u001b[0mall_rules_completed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'============================================='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1481\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1482\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   1092\u001b[0m                 ),\n\u001b[1;32m   1093\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m             )\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job VanishingGradient-33e47daec3c768a56aa1df7156bbf153: Failed. Reason: InternalServerError: We encountered an internal error. Please try again."
     ]
    }
   ],
   "source": [
    "sagemaker_mnist_estimator.describe_rule_execution_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_mnist_estimator.attach(sagemaker_mnist_estimator.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}