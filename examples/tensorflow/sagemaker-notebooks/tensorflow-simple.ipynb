{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging SageMaker Training Jobs with Tornasole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tornasole is a new capability of Amazon SageMaker that allows debugging machine learning training. It lets you go beyond just looking at scalars like losses and accuracies during training and gives you full visibility into all tensors 'flowing through the graph' during training or inference.\n",
    "\n",
    "Using Tornasole is a two step process:\n",
    "\n",
    "### Saving tensors\n",
    "\n",
    "Tensors define the state of the training job at any particular instant in its lifecycle. Tornasole exposes a library which allows you to capture these tensors and save them for analysis\n",
    "\n",
    "### Analysis\n",
    "\n",
    "Analyses of the tensors emitted is captured by the Tornasole concept called ***Rules***. On a very broad level, Rules are a piece of analysis code that one writes to compares tensors across steps of a training job and analyze them in each step of the training job.\n",
    "You can also analyze raw tensor data outside of the Rules construct using our analysis APIs. Please refer [DeveloperGuide_Rules.md](../../../rules/DeveloperGuide_Rules.md)\n",
    "\n",
    "The analysis of tensors saved requires the package `tornasole.rules`.\n",
    "\n",
    "This example guides you through installation of the required components for emitting tensors in a SageMaker training job and applying a rule over the tensors to monitor the live status of the job. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "As a first step, we'll do the installation of required tools which will allow emission of tensors (saving tensors) and application of rules to analyze them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://tornasole-external-preview-use1/sdk/sagemaker-1.35.2.dev0.tar.gz to ./sagemaker-1.35.2.dev0.tar.gz\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "download: s3://tornasole-external-preview-use1/sdk/sagemaker-tornasole.json to ./sagemaker-tornasole.json\n",
      "\n",
      "Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://tornasole-external-preview-use1/sdk/sagemaker-1.35.2.dev0.tar.gz .\n",
    "!pip -q install sagemaker-1.35.2.dev0.tar.gz\n",
    "!aws s3 cp s3://tornasole-external-preview-use1/sdk/sagemaker-tornasole.json .\n",
    "!aws configure add-model --service-model sagemaker-tornasole.json --service-name sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've completed the setup, we're ready to spin off a training job with debugging enabled\n",
    "\n",
    "## Training with Script Mode\n",
    "\n",
    "We'll be training a TensorFlow model for Sentiment Analysis. This will be done using SageMaker TensorFlow 1.14 Container with Script Mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs\n",
    "\n",
    "Configuring the inputs for the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point_script = 'scripts/simple.py'\n",
    "docker_image_name= '072677473360.dkr.ecr.us-west-2.amazonaws.com/tornasole-preprod-tf-1.13.1-cpu:latest'\n",
    "hyperparameters = {'epochs': 1, 'batch_size': 128}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters\n",
    "Now we'll call the TensorFlow Estimator to kick off a training job. The new parameters in the Estimator to look out for are\n",
    "\n",
    "##### `debug` (bool)\n",
    "This indicates that debugging should be enabled for the training job. Setting this as `True` would make Tornasole available for use with the job\n",
    "\n",
    "##### `rules_specification` (list[*dict*])\n",
    "This is a list of python dictionaries, where each `dict` is of the following form:\n",
    "```\n",
    "{\n",
    "    \"RuleName\": <str> # The name of the class implementing the Tornasole Rule interface. (required)\n",
    "    \"RuleEvaluatorImage\": <str> # The ECR location of rule evaluator image. Not required if first-party rule is used.\n",
    "    \"SourceS3Uri\": <str> # S3 URI of the rule script containing the class in 'RuleName'. If left empty, it would look for the class in one of the First Party rules already provided to you by Amazon. If not, SageMaker will try to look for the rule class in the script\n",
    "    \"InstanceType\": <str> # The ml instance type in which the rule evaluation should run\n",
    "    \"VolumeSizeInGB\": <int> # The volume size to store the runtime artifacts from the rule evaluation\n",
    "    \"RuntimeConfigurations\": {\n",
    "        # Map defining the parameters required to instantiate the Rule class and invoke the rule\n",
    "        <str>: <str>\n",
    "    }\n",
    "}\n",
    "```\n",
    "#### Storage\n",
    "The tensors are, by default, stored in the S3 output path of the training job, under the folder **`/tensors-<job name>`**. This is done to ensure that we don't end up accidentally overwriting the tensors from a training job with the others. Rules evaluation require separation of the tensors paths to be evaluated correctly.\n",
    "\n",
    "If you don't provide an S3 output path to the estimator, SageMaker creates one for you as:\n",
    "**`s3://sagemaker-<region>-<account_id>/`**\n",
    "\n",
    "See the way we instantiate the estimator below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule\n",
    "\n",
    "There are two ways to apply rules.\n",
    "1. Use a 1P rule. Specify the RuleName with the 1P RuleName, and the rule will be automatically applied. Here we are uing **`VanishingGradient`**. Leave `SourceS3Uri` empty if a 1P rule is needed.\n",
    "2. Use a custom rule script and specify the S3 location of the script in `SourceS3Uri`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(role=sagemaker.get_execution_role(),\n",
    "                  base_job_name='tensorflow-simple-3',\n",
    "                  train_instance_count=1,\n",
    "                  train_instance_type='ml.m4.xlarge',\n",
    "                  image_name=docker_image_name,\n",
    "                  entry_point=entry_point_script,\n",
    "                  framework_version='1.4.1',\n",
    "                  py_version='py3',\n",
    "                  script_mode=True,\n",
    "                  model_dir='/opt/ml/model',\n",
    "                  #hyperparameters=hyperparameters,\n",
    "                  debug=True,\n",
    "                  train_max_run=1800,\n",
    "                  rules_specification=[\n",
    "                      {\n",
    "                          \"RuleName\": \"WeightUpdateRatio\",\n",
    "                          # \"SourceS3Uri\": \"s3://weiyou-tornasole-test/rule-script/check_grads.py\",\n",
    "                          \"InstanceType\": \"ml.c5.4xlarge\",\n",
    "                          \"VolumeSizeInGB\": 10,\n",
    "                          #\"RuntimeConfigurations\": {\n",
    "                          #    \"start-step\": \"1\",\n",
    "                          #    \"end-step\": \"50\"\n",
    "                          #}\n",
    "                      }\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-20 21:34:30 Starting - Starting the training job...\n",
      "2019-08-20 21:34:32 Starting - Launching requested ML instances......\n",
      "2019-08-20 21:35:35 Starting - Preparing the instances for training...\n",
      "2019-08-20 21:36:19 Downloading - Downloading input data\n",
      "2019-08-20 21:36:19 Training - Downloading the training image......\n",
      "2019-08-20 21:37:29 Uploading - Uploading generated training model\n",
      "2019-08-20 21:37:29 Completed - Training job completed\n",
      "\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:20,619 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:20,625 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:20,941 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:20,959 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:20,976 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:20,989 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"/opt/ml/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tensorflow-simple-3-2019-08-20-21-34-29-729\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-072677473360/tensorflow-simple-3-2019-08-20-21-34-29-729/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"simple\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"simple.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HPS={\"model_dir\":\"/opt/ml/model\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=simple.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=simple\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-us-west-2-072677473360/tensorflow-simple-3-2019-08-20-21-34-29-729/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_dir\":\"/opt/ml/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-simple-3-2019-08-20-21-34-29-729\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-072677473360/tensorflow-simple-3-2019-08-20-21-34-29-729/source/sourcedir.tar.gz\",\"module_name\":\"simple\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"simple.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--model_dir\",\"/opt/ml/model\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_HP_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/local/bin/python simple.py --model_dir /opt/ml/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[31mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mColocations handled automatically by placer.\u001b[0m\n",
      "\u001b[31mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mColocations handled automatically by placer.\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:22.766 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:114] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:22.786 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:234] Saving the collection gradients with 1 tensors and 0 reductions for 0 tensors.\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:22.787 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:234] Saving the collection all with 106 tensors and 0 reductions for 0 tensors.\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:22.788 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:234] Saving the collection weights with 1 tensors and 0 reductions for 0 tensors.\u001b[0m\n",
      "\u001b[31mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tornasole/tensorflow/hook.py:273: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mUse tf.compat.v1.graph_util.extract_sub_graph\u001b[0m\n",
      "\u001b[31mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tornasole/tensorflow/hook.py:273: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mUse tf.compat.v1.graph_util.extract_sub_graph\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.203216: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.203266: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.203280: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.203309: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.203339: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:23.204 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:364] Saving for step 0: 90 objects\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:23.225 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:376] Save complete, saved 1470 bytes\u001b[0m\n",
      "\u001b[31mStep=0, Loss=67.32943725585938\u001b[0m\n",
      "\u001b[31mStep=1, Loss=106.45069885253906\u001b[0m\n",
      "\u001b[31mStep=2, Loss=76.3190689086914\u001b[0m\n",
      "\u001b[31mStep=3, Loss=52.200225830078125\u001b[0m\n",
      "\u001b[31mStep=4, Loss=111.14265441894531\u001b[0m\n",
      "\u001b[31mStep=5, Loss=100.64378356933594\u001b[0m\n",
      "\u001b[31mStep=6, Loss=66.68940734863281\u001b[0m\n",
      "\u001b[31mStep=7, Loss=103.21635437011719\u001b[0m\n",
      "\u001b[31mStep=8, Loss=87.09513092041016\u001b[0m\n",
      "\u001b[31mStep=9, Loss=84.50748443603516\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.305059: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.305090: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.305102: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.305133: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.305171: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:23.306 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:364] Saving for step 10: 90 objects\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:23.325 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:376] Save complete, saved 1470 bytes\u001b[0m\n",
      "\u001b[31mStep=10, Loss=55.7346305847168\u001b[0m\n",
      "\u001b[31mStep=11, Loss=102.39830017089844\u001b[0m\n",
      "\u001b[31mStep=12, Loss=83.6202621459961\u001b[0m\n",
      "\u001b[31mStep=13, Loss=124.57389068603516\u001b[0m\n",
      "\u001b[31mStep=14, Loss=75.1689682006836\u001b[0m\n",
      "\u001b[31mStep=15, Loss=64.03076171875\u001b[0m\n",
      "\u001b[31mStep=16, Loss=88.12054443359375\u001b[0m\n",
      "\u001b[31mStep=17, Loss=97.16738891601562\u001b[0m\n",
      "\u001b[31mStep=18, Loss=75.51183319091797\u001b[0m\n",
      "\u001b[31mStep=19, Loss=102.95091247558594\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.335369: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.335401: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.335419: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.335455: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.335492: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:23.336 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:364] Saving for step 20: 90 objects\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:23.355 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:376] Save complete, saved 1470 bytes\u001b[0m\n",
      "\u001b[31mStep=20, Loss=88.21834564208984\u001b[0m\n",
      "\u001b[31mStep=21, Loss=142.20205688476562\u001b[0m\n",
      "\u001b[31mStep=22, Loss=69.80048370361328\u001b[0m\n",
      "\u001b[31mStep=23, Loss=67.06889343261719\u001b[0m\n",
      "\u001b[31mStep=24, Loss=70.43071746826172\u001b[0m\n",
      "\u001b[31mStep=25, Loss=97.67887878417969\u001b[0m\n",
      "\u001b[31mStep=26, Loss=106.34376525878906\u001b[0m\n",
      "\u001b[31mStep=27, Loss=112.52400970458984\u001b[0m\n",
      "\u001b[31mStep=28, Loss=94.1623764038086\u001b[0m\n",
      "\u001b[31mStep=29, Loss=85.87613677978516\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.364733: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.364770: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.364791: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.364827: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.364861: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:23.365 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:364] Saving for step 30: 90 objects\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:23.387 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:376] Save complete, saved 1470 bytes\u001b[0m\n",
      "\u001b[31mStep=30, Loss=76.36686706542969\u001b[0m\n",
      "\u001b[31mStep=31, Loss=95.54371643066406\u001b[0m\n",
      "\u001b[31mStep=32, Loss=109.13365173339844\u001b[0m\n",
      "\u001b[31mStep=33, Loss=116.1116943359375\u001b[0m\n",
      "\u001b[31mStep=34, Loss=79.13614654541016\u001b[0m\n",
      "\u001b[31mStep=35, Loss=123.3012924194336\u001b[0m\n",
      "\u001b[31mStep=36, Loss=121.37321472167969\u001b[0m\n",
      "\u001b[31mStep=37, Loss=95.31197357177734\u001b[0m\n",
      "\u001b[31mStep=38, Loss=42.02855682373047\u001b[0m\n",
      "\u001b[31mStep=39, Loss=111.04630279541016\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.402241: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.402287: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.402312: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.402354: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.402395: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:23.403 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:364] Saving for step 40: 90 objects\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:23.427 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:376] Save complete, saved 1470 bytes\u001b[0m\n",
      "\u001b[31mStep=40, Loss=97.73392486572266\u001b[0m\n",
      "\u001b[31mStep=41, Loss=57.79924392700195\u001b[0m\n",
      "\u001b[31mStep=42, Loss=89.85606384277344\u001b[0m\n",
      "\u001b[31mStep=43, Loss=78.11842346191406\u001b[0m\n",
      "\u001b[31mStep=44, Loss=93.9296875\u001b[0m\n",
      "\u001b[31mStep=45, Loss=95.96855163574219\u001b[0m\n",
      "\u001b[31mStep=46, Loss=75.94319152832031\u001b[0m\n",
      "\u001b[31mStep=47, Loss=92.52357482910156\u001b[0m\n",
      "\u001b[31mStep=48, Loss=92.52596282958984\u001b[0m\n",
      "\u001b[31mStep=49, Loss=95.1946792602539\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.438528: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.438561: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.438574: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.438606: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.438643: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:23.439 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:364] Saving for step 50: 90 objects\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:23.458 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:376] Save complete, saved 1470 bytes\u001b[0m\n",
      "\u001b[31mStep=50, Loss=62.85589599609375\u001b[0m\n",
      "\u001b[31mStep=51, Loss=91.59235382080078\u001b[0m\n",
      "\u001b[31mStep=52, Loss=111.5092544555664\u001b[0m\n",
      "\u001b[31mStep=53, Loss=69.8747329711914\u001b[0m\n",
      "\u001b[31mStep=54, Loss=46.43537139892578\u001b[0m\n",
      "\u001b[31mStep=55, Loss=81.3962173461914\u001b[0m\n",
      "\u001b[31mStep=56, Loss=89.29122161865234\u001b[0m\n",
      "\u001b[31mStep=57, Loss=133.05877685546875\u001b[0m\n",
      "\u001b[31mStep=58, Loss=120.92208099365234\u001b[0m\n",
      "\u001b[31mStep=59, Loss=58.299232482910156\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.468957: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.469014: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.469029: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.469065: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.469104: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:23.469 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:364] Saving for step 60: 90 objects\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:23.491 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:376] Save complete, saved 1470 bytes\u001b[0m\n",
      "\u001b[31mStep=60, Loss=134.35777282714844\u001b[0m\n",
      "\u001b[31mStep=61, Loss=70.82164001464844\u001b[0m\n",
      "\u001b[31mStep=62, Loss=60.53596115112305\u001b[0m\n",
      "\u001b[31mStep=63, Loss=56.17475128173828\u001b[0m\n",
      "\u001b[31mStep=64, Loss=98.62440490722656\u001b[0m\n",
      "\u001b[31mStep=65, Loss=74.22132873535156\u001b[0m\n",
      "\u001b[31mStep=66, Loss=108.59844970703125\u001b[0m\n",
      "\u001b[31mStep=67, Loss=129.8321990966797\u001b[0m\n",
      "\u001b[31mStep=68, Loss=55.25238037109375\u001b[0m\n",
      "\u001b[31mStep=69, Loss=50.769020080566406\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.501205: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.501236: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.501249: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.501281: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.501314: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:23.502 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:364] Saving for step 70: 90 objects\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:23.521 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:376] Save complete, saved 1470 bytes\u001b[0m\n",
      "\u001b[31mStep=70, Loss=105.72215270996094\u001b[0m\n",
      "\u001b[31mStep=71, Loss=94.40794372558594\u001b[0m\n",
      "\u001b[31mStep=72, Loss=101.28347778320312\u001b[0m\n",
      "\u001b[31mStep=73, Loss=90.53974151611328\u001b[0m\n",
      "\u001b[31mStep=74, Loss=74.01187896728516\u001b[0m\n",
      "\u001b[31mStep=75, Loss=115.82781982421875\u001b[0m\n",
      "\u001b[31mStep=76, Loss=84.9361572265625\u001b[0m\n",
      "\u001b[31mStep=77, Loss=75.29060363769531\u001b[0m\n",
      "\u001b[31mStep=78, Loss=118.1702651977539\u001b[0m\n",
      "\u001b[31mStep=79, Loss=86.40904235839844\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.531345: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.531381: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.531403: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.531441: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.531479: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:23.532 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:364] Saving for step 80: 90 objects\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:23.551 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:376] Save complete, saved 1470 bytes\u001b[0m\n",
      "\u001b[31mStep=80, Loss=97.13294219970703\u001b[0m\n",
      "\u001b[31mStep=81, Loss=46.97969436645508\u001b[0m\n",
      "\u001b[31mStep=82, Loss=120.34873962402344\u001b[0m\n",
      "\u001b[31mStep=83, Loss=34.44107437133789\u001b[0m\n",
      "\u001b[31mStep=84, Loss=88.86713409423828\u001b[0m\n",
      "\u001b[31mStep=85, Loss=132.03033447265625\u001b[0m\n",
      "\u001b[31mStep=86, Loss=88.00300598144531\u001b[0m\n",
      "\u001b[31mStep=87, Loss=70.3223648071289\u001b[0m\n",
      "\u001b[31mStep=88, Loss=78.8561019897461\u001b[0m\n",
      "\u001b[31mStep=89, Loss=80.96626281738281\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.561652: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.561684: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.561697: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.561731: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23.561767: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:23.562 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:364] Saving for step 90: 90 objects\u001b[0m\n",
      "\u001b[31m[2019-08-20 21:37:23.581 ip-10-0-160-72.us-west-2.compute.internal:23 INFO hook.py:376] Save complete, saved 1470 bytes\u001b[0m\n",
      "\u001b[31mStep=90, Loss=64.75139617919922\u001b[0m\n",
      "\u001b[31mStep=91, Loss=103.0936508178711\u001b[0m\n",
      "\u001b[31mStep=92, Loss=99.81513214111328\u001b[0m\n",
      "\u001b[31mStep=93, Loss=47.25444412231445\u001b[0m\n",
      "\u001b[31mStep=94, Loss=96.11323547363281\u001b[0m\n",
      "\u001b[31mStep=95, Loss=75.98189544677734\u001b[0m\n",
      "\u001b[31mStep=96, Loss=70.39654541015625\u001b[0m\n",
      "\u001b[31mStep=97, Loss=91.01075744628906\u001b[0m\n",
      "\u001b[31mStep=98, Loss=76.5438232421875\u001b[0m\n",
      "\u001b[31mStep=99, Loss=109.74250793457031\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23,771 sagemaker_tensorflow_container.training WARNING  No model artifact is saved under path /opt/ml/model. Your training job will not save any model files to S3.\u001b[0m\n",
      "\u001b[31mFor details of how to construct your training script see:\u001b[0m\n",
      "\u001b[31mhttps://github.com/aws/sagemaker-python-sdk/tree/master/src/sagemaker/tensorflow#adapting-your-local-tensorflow-script\u001b[0m\n",
      "\u001b[31m2019-08-20 21:37:23,771 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Billable seconds: 77\n"
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "As a result of the above command, SageMaker will spin off 2 training jobs for you - the first one being the job which produces the tensors to be analyzed and the second one, which evaluates or analyzes the rule you asked it to in `rules_specification`\n",
    "\n",
    "### Check the status of the Rule Execution Job\n",
    "To get the rule execution job that SageMaker started for you, run the command below and it shows you the `RuleName`, `RuleStatus`, `FailureReason` if any, and `RuleExecutionJobArn`. If the tensors meets a rule evaluation condition, the rule execution job throws a client error with `FailureReason: RuleEvaluationConditionMet`. You can check the Cloudwatch Logstream `/aws/sagemaker/TrainingJobs` with `RuleExecutionJobArn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuleName: WeightUpdateRatio\n",
      "RuleStatus: NotStarted\n"
     ]
    }
   ],
   "source": [
    "estimator.describe_rule_execution_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receive CloudWatch Event For your Jobs\n",
    "When the status of training job or rule execution job change (i.e. starting, failed), TrainingJobStatus CloudWatch events are emitted : https://docs.aws.amazon.com/sagemaker/latest/dg/cloudwatch-events.html. You can configure a CW event rule to receive and process these events by setting up a target (Lambda function, SNS). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}